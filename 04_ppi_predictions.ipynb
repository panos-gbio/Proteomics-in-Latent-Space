{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import metrics, random forest, svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score,precision_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, PrecisionRecallDisplay, auc, precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(os.getcwd() + \"\\\\data\\\\processed\\\\features_final_merge.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance on default RF classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04996692, 0.0585296 , 0.32309847, 0.14822497, 0.05140692,\n",
       "       0.05282734, 0.04689774, 0.03453662, 0.0315694 , 0.03411826,\n",
       "       0.03103834, 0.03169341, 0.07314336, 0.03294865])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = \"SCBC\"\n",
    "seed = 236\n",
    "# feature_list = list(importance_df.head(5).index)\n",
    "\n",
    "# sample from the data and undersample the negative class by random shuffling\n",
    "pos_df = data[data[\"db\"] == 1]\n",
    "neg_df = data[data[\"db\"] == 0]\n",
    "neg_df = neg_df.sample(n=pos_df.shape[0], random_state=seed)\n",
    "data_sample = pd.concat([pos_df, neg_df])\n",
    "del pos_df, neg_df\n",
    "\n",
    "# shuffle the data\n",
    "data_sample = data_sample.sample(frac=1, random_state=seed)\n",
    "\n",
    "# subset columns of data df based on regex\n",
    "X_df = data_sample.filter(regex=subset)\n",
    "\n",
    "X = data_sample.filter(regex=subset)\n",
    "y = data_sample[\"db\"]\n",
    "\n",
    "# scale the data\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=X_df.columns)\n",
    "\n",
    "# split train-test sets from this seed \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "# train a randomforest classifier, set max features to 0.5\n",
    "rf = RandomForestClassifier(n_estimators=250,\n",
    "                            max_features=0.8, \n",
    "                            criterion=\"entropy\",\n",
    "                            random_state=seed,\n",
    "                            min_samples_leaf=10,\n",
    "                            max_depth=12)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7511783649700702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.71      3252\n",
      "           1       0.73      0.59      0.66      3358\n",
      "\n",
      "    accuracy                           0.68      6610\n",
      "   macro avg       0.69      0.68      0.68      6610\n",
      "weighted avg       0.69      0.68      0.68      6610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predprob = rf.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, y_predprob))\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pearson_ABMS_raw</th>\n",
       "      <td>0.323098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman_ABMS_raw</th>\n",
       "      <td>0.148225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABMS_raw_std_dif</th>\n",
       "      <td>0.073143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manhattan_ABMS_raw</th>\n",
       "      <td>0.058530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euclidean_ABMS_umap</th>\n",
       "      <td>0.052827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine_ABMS_umap</th>\n",
       "      <td>0.051407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euclidean_ABMS_raw</th>\n",
       "      <td>0.049967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manhattan_ABMS_umap</th>\n",
       "      <td>0.046898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine_ABMS_vae</th>\n",
       "      <td>0.034537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manhattan_ABMS_vae</th>\n",
       "      <td>0.034118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "pearson_ABMS_raw       0.323098\n",
       "spearman_ABMS_raw      0.148225\n",
       "ABMS_raw_std_dif       0.073143\n",
       "manhattan_ABMS_raw     0.058530\n",
       "euclidean_ABMS_umap    0.052827\n",
       "cosine_ABMS_umap       0.051407\n",
       "euclidean_ABMS_raw     0.049967\n",
       "manhattan_ABMS_umap    0.046898\n",
       "cosine_ABMS_vae        0.034537\n",
       "manhattan_ABMS_vae     0.034118"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_df = pd.DataFrame(rf.feature_importances_, index=X_train.columns, columns=[\"importance\"])\n",
    "importance_df = importance_df.sort_values(by=\"importance\", ascending=False)\n",
    "# feature_list_imp = list(importance_df.head(10).index)\n",
    "importance_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Analysis Linear Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruned Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ABMS_raw_std_diff'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# subset columns of data df based on choices\u001b[39;00m\n\u001b[32m      2\u001b[39m feature_list = [\u001b[33m\"\u001b[39m\u001b[33mpearson_SCBC_raw\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mABMS_raw_std_dif\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mABMS_vae_std_dif\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_df = \u001b[43mdata_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpearson_SCBC_raw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mABMS_raw_std_diff\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      5\u001b[39m X = data_sample[[\u001b[33m\"\u001b[39m\u001b[33mpearson_SCBC_raw\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mABMS_raw_std_diff\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m      6\u001b[39m y = data_sample[\u001b[33m\"\u001b[39m\u001b[33mdb\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gpano\\anaconda3\\envs\\scbc3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gpano\\anaconda3\\envs\\scbc3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gpano\\anaconda3\\envs\\scbc3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['ABMS_raw_std_diff'] not in index\""
     ]
    }
   ],
   "source": [
    "# subset columns of data df based on choices\n",
    "feature_list = [\"pearson_ABMS_raw\", \"spearman_ABMS_raw\",\"ABMS_raw_std_dif\",\"ABMS_vae_std_dif\", \"manhattan_ABMS_raw\"]\n",
    "X_df = data_sample[[\"pearson_SCBC_raw\", \"ABMS_raw_std_dif\"]]\n",
    "\n",
    "X = data_sample[[\"pearson_SCBC_raw\", \"ABMS_raw_std_dif\"]]\n",
    "y = data_sample[\"db\"]\n",
    "\n",
    "# scale the data\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=X_df.columns)\n",
    "\n",
    "# split train-test sets from this seed \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# train a randomforest classifier, set max features to 0.5\n",
    "rf2 = RandomForestClassifier(n_estimators=500,\n",
    "                            max_features=\"sqrt\", \n",
    "                            criterion=\"entropy\",\n",
    "                            random_state=seed,\n",
    "                            min_samples_leaf=25,\n",
    "                            max_depth=None)\n",
    "rf2.fit(X_train, y_train)\n",
    "rf2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      3283\n",
      "           1       0.65      0.65      0.65      3327\n",
      "\n",
      "    accuracy                           0.65      6610\n",
      "   macro avg       0.65      0.65      0.65      6610\n",
      "weighted avg       0.65      0.65      0.65      6610\n",
      "\n",
      "0.6983442772153476\n"
     ]
    }
   ],
   "source": [
    "Y_pred2 = rf2.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, Y_pred2))\n",
    "\n",
    "Y_predprob2 = rf2.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, Y_predprob2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1655484    0.331571\n",
       "3200652    0.304377\n",
       "4615155    0.618195\n",
       "2952380    0.609667\n",
       "1647539    0.266003\n",
       "             ...   \n",
       "792418     0.892910\n",
       "808293     0.485766\n",
       "3003705    0.377529\n",
       "3496674    0.358185\n",
       "110612     0.309180\n",
       "Name: ABMS_raw_std_dif, Length: 33048, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample[\"ABMS_vae_std_dif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "0.7413114355979772\n"
     ]
    }
   ],
   "source": [
    "# subset columns of data df based on regex\n",
    "feature_list = data_sample.columns[data_sample.columns.str.contains(\"ABMS\")]\n",
    "X_df = data_sample[feature_list]\n",
    "\n",
    "X = data_sample[feature_list]\n",
    "y = data_sample[\"db\"]\n",
    "\n",
    "# split train-test sets from this seed \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "classifier_pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(penalty=\"l2\", solver=\"liblinear\", random_state=seed))\n",
    "    ])\n",
    "\n",
    "param_grid = {\n",
    "        'logreg__C': [0.005,0.01,0.05,0.1]\n",
    "    }\n",
    "# create a cv fold\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "grid = GridSearchCV(classifier_pipe, param_grid, cv=10, scoring='roc_auc', n_jobs=4, verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "model_best = grid.best_estimator_\n",
    "# get probabilities back for roc auc\n",
    "Y_pred3 = model_best.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, Y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pearson_ABMS_raw',\n",
       " 'spearman_ABMS_raw',\n",
       " 'ABMS_raw_std_dif',\n",
       " 'manhattan_ABMS_raw',\n",
       " 'cosine_ABMS_umap',\n",
       " 'euclidean_ABMS_umap',\n",
       " 'manhattan_ABMS_umap',\n",
       " 'euclidean_ABMS_raw',\n",
       " 'manhattan_ABMS_vae',\n",
       " 'cosine_ABMS_vae']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12559      1\n",
       "613860     1\n",
       "4545307    0\n",
       "2611044    1\n",
       "141790     0\n",
       "          ..\n",
       "1121252    1\n",
       "4192548    0\n",
       "3717421    0\n",
       "718859     1\n",
       "1225442    0\n",
       "Name: db, Length: 6610, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "0.7403675897985902\n"
     ]
    }
   ],
   "source": [
    "# subset columns of data df based on regex\n",
    "# feature_list = [\"pearson_ABMS_raw\", \"spearman_ABMS_raw\",\"ABMS_raw_std_dif\",\"ABMS_vae_std_dif\", \"manhattan_ABMS_raw\",\"euclidean_ABMS_umap\"]\n",
    "feature_list = data_sample.columns[data_sample.columns.str.contains(\"ABMS\")]\n",
    "X_df = data_sample[feature_list]\n",
    "\n",
    "X = data_sample[feature_list]\n",
    "y = data_sample[\"db\"]\n",
    "\n",
    "# split train-test sets from this seed \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "svm_classifier_pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm\", SVC(kernel=\"rbf\", probability=True, random_state=seed))\n",
    "    ])\n",
    "\n",
    "# param_grid = {\n",
    "#         'svm_C': [0.05,0.1,1,10],\n",
    "#         'svm_gamma': [\"scale\",\"auto\",\"0.01\",\"0.1\",\"1\"]\n",
    "#     }  \n",
    "\n",
    "param_grid = {\n",
    "        'svm__C': [0.1,1,2,5],\n",
    "        'svm__gamma': [0.001,0.05,0.01,0.1,1]\n",
    "    }  \n",
    "# create a cv fold\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "svm_grid = GridSearchCV(svm_classifier_pipe, param_grid, cv=10, scoring='roc_auc', n_jobs=5, verbose=1)\n",
    "\n",
    "svm_grid.fit(X_train, y_train)\n",
    "model_best_svm = svm_grid.best_estimator_\n",
    "\n",
    "# get probabilities back for roc auc\n",
    "Y_pred4 = model_best_svm.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, Y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model parameters\n",
    "joblib.dump(svm_grid,os.getcwd() + \"\\\\data\\\\processed\\\\svm_radial_CV_ABMS.joblib\")\n",
    "\n",
    "pd.DataFrame(svm_grid.cv_results_).to_csv(os.getcwd() + \"\\\\data\\\\processed\\\\svm_radial_CV_ABMS.csv\")\n",
    "# SAVE CV results too\n",
    "\n",
    "\n",
    "# os.getcwd() + \"\\\\data\\\\processed\\\\svm_linear_CV_ABMS.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n",
      "0.8096387012857621\n"
     ]
    }
   ],
   "source": [
    "# subset columns of data df based on regex\n",
    "# feature_list = [\"pearson_ABMS_raw\", \"spearman_ABMS_raw\",\"ABMS_raw_std_dif\",\"ABMS_vae_std_dif\", \"manhattan_ABMS_raw\",\"euclidean_ABMS_umap\"]\n",
    "feature_list = data_sample.columns[data_sample.columns.str.contains(\"SCBC\")]\n",
    "X_df = data_sample[feature_list]\n",
    "\n",
    "X = data_sample[feature_list]\n",
    "y = data_sample[\"db\"]\n",
    "\n",
    "# split train-test sets from this seed \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "svm_classifier_pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm\", SVC(kernel=\"rbf\", probability=True, random_state=seed))\n",
    "    ])\n",
    "\n",
    "# param_grid = {\n",
    "#         'svm_C': [0.05,0.1,1,10],\n",
    "#         'svm_gamma': [\"scale\",\"auto\",\"0.01\",\"0.1\",\"1\"]\n",
    "#     }  \n",
    "\n",
    "param_grid = {\n",
    "        'svm__C': [0.05,0.1,1,2,5],\n",
    "        'svm__gamma': [0.001,0.05,0.01,0.1,1]\n",
    "    }  \n",
    "# create a cv fold\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "svm_grid = GridSearchCV(svm_classifier_pipe, param_grid, cv=10, scoring='roc_auc', n_jobs=6, verbose=1)\n",
    "\n",
    "svm_grid.fit(X_train, y_train)\n",
    "model_best_svm = svm_grid.best_estimator_\n",
    "\n",
    "# get probabilities back for roc auc\n",
    "Y_pred4 = model_best_svm.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, Y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model parameters\n",
    "joblib.dump(svm_grid,os.getcwd() + \"\\\\data\\\\processed\\\\svm_radial_CV_SCBC.joblib\")\n",
    "\n",
    "pd.DataFrame(svm_grid.cv_results_).to_csv(os.getcwd() + \"\\\\data\\\\processed\\\\svm_radial_CV_SCBC.csv\")\n",
    "# SAVE CV results too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpd\u001b[49m.DataFrame(svm_grid.cv_results_).sort_values\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(svm_grid.cv_results_).sort_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gpano\\anaconda3\\envs\\scbc3\\Lib\\site-packages\\sklearn\\base.py:236: FutureWarning: Parameter 'base_estimator' of CalibratedClassifierCV is deprecated in favor of 'estimator'. See CalibratedClassifierCV's docstring for more details.\n",
      "  valid_params[key].set_params(**sub_params)\n",
      "c:\\Users\\gpano\\anaconda3\\envs\\scbc3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gpano\\anaconda3\\envs\\scbc3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gpano\\anaconda3\\envs\\scbc3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gpano\\anaconda3\\envs\\scbc3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8026776147190808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gpano\\anaconda3\\envs\\scbc3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# subset columns of data df based on regex\n",
    "# feature_list = [\"pearson_ABMS_raw\", \"spearman_ABMS_raw\",\"ABMS_raw_std_dif\",\"ABMS_vae_std_dif\", \"manhattan_ABMS_raw\",\"euclidean_ABMS_umap\"]\n",
    "seed = 236\n",
    "# feature_list = list(importance_df.head(5).index)\n",
    "\n",
    "# sample from the data and undersample the negative class by random shuffling\n",
    "pos_df = data[data[\"db\"] == 1]\n",
    "neg_df = data[data[\"db\"] == 0]\n",
    "neg_df = neg_df.sample(n=pos_df.shape[0], random_state=seed)\n",
    "\n",
    "data_sample = pd.concat([pos_df, neg_df])\n",
    "del pos_df, neg_df\n",
    "\n",
    "feature_list = data_sample.columns[data_sample.columns.str.contains(\"SCBC\")]\n",
    "X_df = data_sample[feature_list]\n",
    "\n",
    "X = data_sample[feature_list]\n",
    "y = data_sample[\"db\"]\n",
    "\n",
    "# split train-test sets from this seed \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "svm_linear_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", CalibratedClassifierCV(\n",
    "              LinearSVC(penalty='l2', loss='squared_hinge', random_state=seed, max_iter=10000),\n",
    "              cv=5))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "        'svm__base_estimator__C': [0.1,0.5,1,2,2.5,5,10]\n",
    "    }  \n",
    "# create a cv fold\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "svm_lgrid = GridSearchCV(svm_linear_pipe, param_grid, cv=10, scoring='roc_auc', n_jobs=6, verbose=1)\n",
    "\n",
    "svm_lgrid.fit(X_train, y_train)\n",
    "model_best_svml = svm_lgrid.best_estimator_\n",
    "\n",
    "# get probabilities back for roc auc\n",
    "Y_pred5 = model_best_svml.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, Y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # save the model parameters\n",
    "joblib.dump(svm_lgrid,os.getcwd() + \"\\\\data\\\\processed\\\\svm_linear_CV_SCBC.joblib\")\n",
    "\n",
    "pd.DataFrame(svm_lgrid.cv_results_).sort_values(by=\"rank_test_score\").to_csv(os.getcwd() + \"\\\\data\\\\processed\\\\svm_linear_CV_SCBC.csv\")\n",
    "# # SAVE CV results too"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scbc3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
