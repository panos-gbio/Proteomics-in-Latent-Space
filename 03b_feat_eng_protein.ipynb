{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the vanila libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# for timing functions\n",
    "from timeit import default_timer as timer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Project Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your current directory\n",
    "savepath = os.getcwd() + \"\\\\data\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** Run the configuration file first `configs.py`. Importing this script and setting the seed and device parameters before importing any of the other modules ensures that evereything is sync.\n",
    "\n",
    "**Important** If you want *change the configuration parameters*, change them before importing and running the pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the configurations values are assigned globally, we can import the modules. If this is working, we expect each module to access the **same** **seed** and **device** we set. We are also expecting generated numbers **inside the modules** to be reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_util import ml_helper as mlh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe with Features\n",
    "\n",
    "Since there are differences between R and python, I tried to combine the advantages of both. In R due to vectorization, it is faster to compute euclidean, manhattan and cosinde distances of matrices (with missing Values too).<br> \n",
    "In python correlation analysis is way faster than R. So...<br>\n",
    "- To speed up python i tried to create custom functions where the distances are calculated via tensor algebra (it speeds things up)\n",
    "- I will be using another matrix from a previous analysis in R to validate that the computations are correct. <br>\n",
    "\n",
    "So for all the feature engineering practices where we have Protein A - Protein B pairs, I used the following naming sceme:<br>\n",
    "\n",
    "```\n",
    "features_dataframe:\n",
    "Var1 - Var2 - [proteomics_type]_[feature_type]_[feature_analysis] - db\n",
    "\n",
    "```\n",
    "**Explanations**:<br>\n",
    "The **Var1** and **Var2** are the protein or sims pairs (unique pairs), where Var1 > Var2 (as a way to remove duplicates and self combinations) <br>\n",
    "The **proteomics type** could be **SCBC** or **ABMS** (subcellular or total cell MS proteomics)<br>\n",
    "The **feature_type** could be the **raw** MS signals, or the **VAE** embeddings, or the **umap** coordinates, <br> \n",
    "The **feature_analysis** could be correlations, distances, angles, or any other feature. If there is time I will perform a **feature importance analysis** in more detail. <br>\n",
    "The **db** are the classes of the classification based on ground truth databases of protein-protein interractions, 0 or 1. If we create the features with the purpose of training a classifier. \n",
    "\n",
    "**Example** of a columns of some features: 'SCBC_raw_pearson', 'ABMS_vae_umap', 'ABMS_vae_euclidean' <br>  \n",
    "**The features dataframe** containing these columns could have protein pairs, proteoform dominant pairs (sims), or all the possible proteoform combinations outhere.<br>\n",
    "\n",
    "**NOTE**<br>\n",
    "For 34 million unique pairs, 14 features require around 32 minutes and do not crash the RAM, that csv file is around 20gb size  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an old file written in R for validation of engineering the features correctly \n",
    "# feat = pd.read_csv(os.getcwd() + \"\\\\data\\\\processed\\\\merged_features_v1.txt\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat[\"db\"] = np.where(feat[\"db\"]==\"F\",0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from Embeddings (VAE, umap) and Raw signals for gene or peptide centric Feature Eng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will construct some features for **protein-protein interractions** or for the **dominant (sim) proteoforms**, which have a corresponding **gene symbol**.<br>\n",
    "- It is the same approach for different protein tables.\n",
    "- The difference lies whether I will use the groudtruth data during feature engineering.\n",
    "- For a subset of protein-protein pairs, which will be used to train the classifier, i will use the ground truth pairs.\n",
    "- For the whole protein matrices, the purpose is to just engineer the features for all possible protein/sims pairs.\n",
    "- This will have impact to the memory of the computer. <br>\n",
    "\n",
    "For the **feature engineering** function we want Dataframes:<br>\n",
    "- where **index** is either gene symbol or any other annotations used. Each row corresponds to a protein, proteoform, etc..\n",
    "- where the **columns** are counts or MS signals (preferable normalized and harmonized) or VAE latent variables or UMAP coordinates. \n",
    "- index is important since we generate pairs and we need to name them or follow them somehow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SOME GLOBAL VARIABLES TO AID THE ANALYSIS ######\n",
    "ANALYSIS_LEVEL = \"proteoform\" # \"protein\" OR \"sims\" for the the dominant proteoforms\n",
    "USE_GROUND_TRUTH = False # if set to TRUE, it subsets the tables based on gene symbols that exist within the PPI databases for every function below \n",
    "seed = 456\n",
    "\n",
    "\n",
    "# USE 3 IF GROUND TRUTH IS TRUE, OTHERWISE 10 ARE ENOUGH \n",
    "BLOCKS = 13 # calculate in a way that each block contains 1000 rows/proteins. So if you have 10000, use 10 blocks, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n",
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n",
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n",
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n",
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n",
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n"
     ]
    }
   ],
   "source": [
    "if ANALYSIS_LEVEL == \"protein\":\n",
    "\n",
    "    # for subcell\n",
    "    raw_scbc = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_protein\\\\protein_quant_merged.txt\", delimiter=\"\\t\", index_col=0)\n",
    "    vae_scbc = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_protein\\\\proteinscbc_latent.csv\", index_col=0)\n",
    "    umap_scbc = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_protein\\\\protein_scbc_umap.csv\", index_col=0)\n",
    "\n",
    "    # for total cell \n",
    "    raw_abms = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_protein\\\\prot_abms_norm.txt\", delimiter=\"\\t\")\n",
    "    vae_abms = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_protein\\\\protein_abms_latent.csv\", index_col=0)\n",
    "    umap_abms = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_protein\\\\protein_abms_umap.csv\", index_col=0)\n",
    "\n",
    "    # for ground truth, the combined CORUM and Compleat datasets in gene symbol format \n",
    "    pairs_df = pd.read_csv(os.getcwd() + \"\\\\data\\\\processed\\\\\" + \"merged_pairs.txt\", delimiter=\"\\t\")\n",
    "\n",
    "elif ANALYSIS_LEVEL == \"sims\":\n",
    "    # for subcell \n",
    "    raw_scbc = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_sim\\\\scbc_quant_sims.csv\", index_col=0)\n",
    "    vae_scbc = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_sim\\\\simscbc_latent.csv\", index_col=0)\n",
    "    umap_scbc = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_sim\\\\sim_scbc_umap.csv\", index_col=0)\n",
    "\n",
    "    # for total cell \n",
    "    raw_abms = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_sim\\\\abms_quant_sims.csv\", index_col=0)\n",
    "    vae_abms = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_sim\\\\sim_abms_latent.csv\", index_col=0)\n",
    "    umap_abms = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_sim\\\\sim_abms_umap.csv\", index_col=0)\n",
    "\n",
    "    # for ground truth, the combined CORUM and Compleat datasets in gene symbol format \n",
    "    pairs_df = pd.read_csv(os.getcwd() + \"\\\\data\\\\processed\\\\\" + \"merged_pairs.txt\", delimiter=\"\\t\")\n",
    "\n",
    "elif ANALYSIS_LEVEL == \"proteoform\":\n",
    "    # overwrite global parameters for proetoform analysis\n",
    "    BLOCK = 13 # many proteoforms in the dataframes \n",
    "    USE_GROUND_TRUTH = False # There is no ground truth for proteoform analysis \n",
    "\n",
    "    # for subcell \n",
    "    raw_scbc = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_proteoforms\\\\SCBC2_proteoform_table 2.txt\", index_col=0, delimiter=\"\\t\")\n",
    "    vae_scbc = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_proteoforms\\\\whole_proteoformscbc_latent.csv\", index_col=0)\n",
    "    umap_scbc = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_proteoforms\\\\whole_proteoform_scbc_umap.csv\", index_col=0)\n",
    "\n",
    "    # filter out proteoform raw data \n",
    "    raw_scbc = raw_scbc.loc[raw_scbc.isna().sum(axis=1) < 0.3*raw_scbc.shape[1]]\n",
    "\n",
    "    # for total cell \n",
    "    raw_abms = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_proteoforms\\\\ABMS_proteoform_table.txt\", decimal=\"\\t\", index_col=0)\n",
    "    vae_abms = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_proteoforms\\\\whole_proteoform_abms_latent.csv\", index_col=0)\n",
    "    umap_abms = pd.read_csv(os.getcwd() + \"\\\\data\\\\features_proteoforms\\\\whole_proteoform_abms_umap.csv\", index_col=0)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Choose either protein tables or dominant proteoform tables (sims) for analysis\")\n",
    "\n",
    "# check for duplicates in the indices and drop them (in case something survived)\n",
    "for df in [raw_scbc, vae_scbc, umap_scbc, raw_abms, vae_abms, umap_abms]:\n",
    "    print(f\"Duplicates in {type(df)} before checking: {df.index.duplicated().sum()}\")\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "# i found some in abms\n",
    "raw_abms = raw_abms.loc[~raw_abms.index.duplicated(keep='first')]\n",
    "vae_abms = vae_abms.loc[~vae_abms.index.duplicated(keep='first')]\n",
    "umap_abms = umap_abms.loc[~umap_abms.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n",
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n",
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n",
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n",
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n",
      "Duplicates in <class 'pandas.core.frame.DataFrame'> before checking: 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates in the indices after clean up \n",
    "for df in [raw_scbc, vae_scbc, umap_scbc, raw_abms, vae_abms, umap_abms]:\n",
    "    print(f\"Duplicates in {type(df)} before checking: {df.index.duplicated().sum()}\")\n",
    "    del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# take random samples around 8000 of the same indices for all the tables\n",
    "rand_index = raw_scbc.sample(4000, random_state=seed).index\n",
    "\n",
    "# subset the protein tables to same indices \n",
    "raw_scbc = raw_scbc.loc[rand_index]\n",
    "vae_scbc = vae_scbc.loc[rand_index]\n",
    "umap_scbc = umap_scbc.loc[rand_index]\n",
    "\n",
    "# check if the order of the indices is the same \n",
    "assert np.array_equal(raw_scbc.index, vae_scbc.index), \"Indices of raw and VAE tables do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 130), (4000, 45), (4000, 3))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dimensions of the tables before run\n",
    "raw_scbc.shape, vae_scbc.shape, umap_scbc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for SubCell (SCBC features dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis is starting for SCBC_raw to get pearson and spearman coefficients\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Perform pairwise correlation analysis for the whole matrix - no ground truth will be used.\n",
      "The number of pairs generated is 7998000\n",
      "Analysis is completed\n",
      "\n",
      "Analysis is starting for SCBC_vae to get pearson and spearman coefficients\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Perform pairwise correlation analysis for the whole matrix - no ground truth will be used.\n",
      "The number of pairs generated is 7998000\n",
      "Analysis is completed\n",
      "\n",
      "Analysis is starting for SCBC_raw for feature manhattan\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Perform pairwise calculation for the whole matrix - no ground truth will be used.\n",
      "The size of each block is 307 rows, and the number of blocks is 13\n",
      "For total number of rows 4000, the number of blocks that are suggested are 3.6363636363636362 rounded up.\n",
      "The number of pairs generated is 7998000\n",
      "Analysis is completed\n",
      "\n",
      "\n",
      "Analysis is starting for SCBC_raw for feature std_difference\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Perform pairwise calculation for the whole matrix - no ground truth will be used.\n",
      "The size of each block is 307 rows, and the number of blocks is 13\n",
      "For total number of rows 4000, the number of blocks that are suggested are 3.6363636363636362 rounded up.\n",
      "The number of pairs generated is 7998000\n",
      "Analysis is completed\n",
      "\n",
      "\n",
      "Analysis is starting for SCBC_umap for feature cosine\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Perform pairwise calculation for the whole matrix - no ground truth will be used.\n",
      "The size of each block is 307 rows, and the number of blocks is 13\n",
      "For total number of rows 4000, the number of blocks that are suggested are 3.6363636363636362 rounded up.\n",
      "The number of pairs generated is 7998000\n",
      "Analysis is completed\n",
      "\n",
      "\n",
      "Analysis is starting for SCBC_umap for feature euclidean\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Perform pairwise calculation for the whole matrix - no ground truth will be used.\n",
      "The size of each block is 307 rows, and the number of blocks is 13\n",
      "For total number of rows 4000, the number of blocks that are suggested are 3.6363636363636362 rounded up.\n",
      "The number of pairs generated is 7998000\n",
      "Analysis is completed\n",
      "\n",
      "\n",
      "Analysis is starting for SCBC_vae for feature cosine\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Perform pairwise calculation for the whole matrix - no ground truth will be used.\n",
      "The size of each block is 307 rows, and the number of blocks is 13\n",
      "For total number of rows 4000, the number of blocks that are suggested are 3.6363636363636362 rounded up.\n",
      "The number of pairs generated is 7998000\n",
      "Analysis is completed\n",
      "\n",
      "\n",
      "The feature dataframe has 7998000 rows and the following columns:\n",
      " ['Var1', 'Var2', 'SCBC_raw_cor_pears', 'SCBC_raw_cor_spear', 'SCBC_vae_cor_pears', 'SCBC_vae_cor_spear', 'SCBC_raw_man', 'SCBC_raw_std_dif', 'SCBC_umap_cos', 'SCBC_umap_euc', 'SCBC_vae_cos']\n",
      "Missing Values in total in the features dataframe: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if USE_GROUND_TRUTH:\n",
    "    ground = pairs_df\n",
    "    merge_cols = [\"Var1\", \"Var2\", \"db\"]\n",
    "else:\n",
    "    ground = None\n",
    "    merge_cols = [\"Var1\", \"Var2\"]\n",
    "\n",
    "# calculate correlation coefficients for all the pairs in raw and VAE tables \n",
    "scbc_raw_corr = mlh.correlation_blockwise(raw_scbc,\n",
    "                                          ground_truth= ground,\n",
    "                                          data_name=\"SCBC_raw\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "scbc_vae_corr = mlh.correlation_blockwise(vae_scbc,\n",
    "                                          ground_truth= ground,\n",
    "                                          data_name=\"SCBC_vae\")\n",
    "gc.collect()\n",
    "\n",
    "scbc_raw_man = mlh.compute_distances_blockwise(raw_scbc,\n",
    "                                        ground_truth = ground,\n",
    "                                        data_name = \"SCBC_raw\",\n",
    "                                        n_chunks = BLOCKS,\n",
    "                                        return_dist = \"manhattan\")\n",
    "gc.collect()\n",
    "\n",
    "scbc_raw_std = mlh.compute_distances_blockwise(raw_scbc,\n",
    "                                        ground_truth = ground,\n",
    "                                        data_name = \"SCBC_raw\",\n",
    "                                        n_chunks = BLOCKS,\n",
    "                                        return_dist = \"std_difference\")\n",
    "gc.collect()\n",
    "\n",
    "scbc_umap_cos = mlh.compute_distances_blockwise(umap_scbc,\n",
    "                                        ground_truth = ground,\n",
    "                                        data_name = \"SCBC_umap\",\n",
    "                                        n_chunks = BLOCKS,\n",
    "                                        return_dist = \"cosine\")\n",
    "gc.collect()\n",
    "\n",
    "scbc_umap_euc = mlh.compute_distances_blockwise(umap_scbc,\n",
    "                                        ground_truth = ground,\n",
    "                                        data_name = \"SCBC_umap\",\n",
    "                                        n_chunks = BLOCKS,\n",
    "                                        return_dist = \"euclidean\")\n",
    "gc.collect()\n",
    "\n",
    "scbc_vae_cos = mlh.compute_distances_blockwise(vae_scbc,\n",
    "                                        ground_truth = ground,\n",
    "                                        data_name = \"SCBC_vae\",\n",
    "                                        n_chunks = BLOCKS,\n",
    "                                        return_dist = \"cosine\")\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# merge the features with all the common values - no missing Values \n",
    "scbc_features = reduce(lambda left, right: pd.merge(left, right, on=merge_cols, how = \"inner\", validate=\"one_to_one\"), [scbc_raw_corr, scbc_vae_corr, scbc_raw_man, scbc_raw_std, scbc_umap_cos, scbc_umap_euc, scbc_vae_cos])\n",
    "\n",
    "# clean memory\n",
    "del scbc_raw_corr, scbc_vae_corr, scbc_raw_man, scbc_raw_std, scbc_umap_cos, scbc_umap_euc, scbc_vae_cos\n",
    "gc.collect()\n",
    "\n",
    "# sanity check \n",
    "print(f\"The feature dataframe has {scbc_features.shape[0]} rows and the following columns:\\n {list(scbc_features.columns)}\")\n",
    "print(f\"Missing Values in total in the features dataframe: {scbc_features.isna().sum().sum()}\\n\")\n",
    "\n",
    "\n",
    "# for consistancy separate and order columns \n",
    "excluded_cols = [col for col in scbc_features.columns if col in merge_cols]\n",
    "other_cols = sorted([col for col in scbc_features.columns if col not in merge_cols])\n",
    "final_col_order = excluded_cols + other_cols\n",
    "\n",
    "# Reorder the DataFrame\n",
    "scbc_features = scbc_features[final_col_order]\n",
    "del excluded_cols, other_cols, final_col_order \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>SCBC_raw_cor_pears</th>\n",
       "      <th>SCBC_raw_cor_spear</th>\n",
       "      <th>SCBC_raw_man</th>\n",
       "      <th>SCBC_raw_std_dif</th>\n",
       "      <th>SCBC_umap_cos</th>\n",
       "      <th>SCBC_umap_euc</th>\n",
       "      <th>SCBC_vae_cor_pears</th>\n",
       "      <th>SCBC_vae_cor_spear</th>\n",
       "      <th>SCBC_vae_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_sim_ENSG00000180817</td>\n",
       "      <td>P_sim_ENSG00000130511</td>\n",
       "      <td>0.113648</td>\n",
       "      <td>0.218177</td>\n",
       "      <td>129.881822</td>\n",
       "      <td>1.474601</td>\n",
       "      <td>0.077247</td>\n",
       "      <td>6.122372</td>\n",
       "      <td>0.348947</td>\n",
       "      <td>0.452964</td>\n",
       "      <td>0.684295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_sim_ENSG00000132424</td>\n",
       "      <td>P_sim_ENSG00000130511</td>\n",
       "      <td>0.776654</td>\n",
       "      <td>0.576658</td>\n",
       "      <td>45.990217</td>\n",
       "      <td>0.540763</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.532088</td>\n",
       "      <td>0.888180</td>\n",
       "      <td>0.888669</td>\n",
       "      <td>0.110640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_sim_ENSG00000182628</td>\n",
       "      <td>P_sim_ENSG00000130511</td>\n",
       "      <td>0.145410</td>\n",
       "      <td>0.232676</td>\n",
       "      <td>86.683385</td>\n",
       "      <td>1.076647</td>\n",
       "      <td>0.051563</td>\n",
       "      <td>4.406766</td>\n",
       "      <td>0.253127</td>\n",
       "      <td>0.274835</td>\n",
       "      <td>0.759528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_sim_ENSG00000163050</td>\n",
       "      <td>P_sim_ENSG00000130511</td>\n",
       "      <td>-0.212615</td>\n",
       "      <td>-0.223659</td>\n",
       "      <td>93.671400</td>\n",
       "      <td>1.046167</td>\n",
       "      <td>0.106859</td>\n",
       "      <td>6.206619</td>\n",
       "      <td>-0.391733</td>\n",
       "      <td>-0.458103</td>\n",
       "      <td>1.359753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_sim_ENSG00000164151</td>\n",
       "      <td>P_sim_ENSG00000130511</td>\n",
       "      <td>0.040685</td>\n",
       "      <td>0.046469</td>\n",
       "      <td>89.952042</td>\n",
       "      <td>1.093471</td>\n",
       "      <td>0.061070</td>\n",
       "      <td>3.985075</td>\n",
       "      <td>0.121424</td>\n",
       "      <td>0.073123</td>\n",
       "      <td>0.875991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Var1                   Var2  SCBC_raw_cor_pears  \\\n",
       "0  P_sim_ENSG00000180817  P_sim_ENSG00000130511            0.113648   \n",
       "1  P_sim_ENSG00000132424  P_sim_ENSG00000130511            0.776654   \n",
       "2  P_sim_ENSG00000182628  P_sim_ENSG00000130511            0.145410   \n",
       "3  P_sim_ENSG00000163050  P_sim_ENSG00000130511           -0.212615   \n",
       "4  P_sim_ENSG00000164151  P_sim_ENSG00000130511            0.040685   \n",
       "\n",
       "   SCBC_raw_cor_spear  SCBC_raw_man  SCBC_raw_std_dif  SCBC_umap_cos  \\\n",
       "0            0.218177    129.881822          1.474601       0.077247   \n",
       "1            0.576658     45.990217          0.540763       0.000762   \n",
       "2            0.232676     86.683385          1.076647       0.051563   \n",
       "3           -0.223659     93.671400          1.046167       0.106859   \n",
       "4            0.046469     89.952042          1.093471       0.061070   \n",
       "\n",
       "   SCBC_umap_euc  SCBC_vae_cor_pears  SCBC_vae_cor_spear  SCBC_vae_cos  \n",
       "0       6.122372            0.348947            0.452964      0.684295  \n",
       "1       0.532088            0.888180            0.888669      0.110640  \n",
       "2       4.406766            0.253127            0.274835      0.759528  \n",
       "3       6.206619           -0.391733           -0.458103      1.359753  \n",
       "4       3.985075            0.121424            0.073123      0.875991  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check for the table \n",
    "scbc_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Var1                  0\n",
       "Var2                  0\n",
       "SCBC_raw_cor_pears    0\n",
       "SCBC_raw_cor_spear    0\n",
       "SCBC_raw_man          0\n",
       "SCBC_raw_std_dif      0\n",
       "SCBC_umap_cos         0\n",
       "SCBC_umap_euc         0\n",
       "SCBC_vae_cor_pears    0\n",
       "SCBC_vae_cor_spear    0\n",
       "SCBC_vae_cos          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scbc_features.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSIS_LEVEL == \"protein\":\n",
    "\n",
    "    if USE_GROUND_TRUTH:\n",
    "        scbc_features.to_csv(savepath + \"features_protein\\\\scbc_protein_features_db2.csv\", header=True)\n",
    "    else:\n",
    "        scbc_features.to_csv(savepath + \"features_protein\\\\scbc_protein_features_full.csv\", header=True)\n",
    "\n",
    "elif ANALYSIS_LEVEL == \"sims\":\n",
    "    \n",
    "    if USE_GROUND_TRUTH:\n",
    "        scbc_features.to_csv(savepath + \"features_sim\\\\scbc_sim_features_db2.csv\", header=True)\n",
    "    else:\n",
    "        scbc_features.to_csv(savepath + \"features_sim\\\\scbc_sim_features_full.csv\", header=True)\n",
    "\n",
    "elif ANALYSIS_LEVEL == \"proteoform\":\n",
    "    scbc_features.to_csv(savepath + \"features_proteoforms\\\\scbc_proteoform_features_full.csv\", header=True)\n",
    "    \n",
    "else:\n",
    "    raise RuntimeError(\"An ANALYSIS_LEVEL has not been specified\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scbc3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
