{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the vanila libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as nrd\n",
    "import os\n",
    "import pathlib \n",
    "import sys\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "#\n",
    "import umap\n",
    "\n",
    "# Pytorch modules \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# this for the custom Dataset \n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "\n",
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# for timing functions\n",
    "from timeit import default_timer as timer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Project Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\gpano\\\\Desktop\\\\github_py\\\\proteomics_latent_space'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check your current directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** Run the configuration file first `configs.py`. Importing this script and setting the seed and device parameters before importing any of the other modules ensures that evereything is sync.\n",
    "\n",
    "**Important** If you want *change the configuration parameters*, change them before importing and running the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing models_util.configs module\n",
      "First set device and seed for reproducibility.\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from models_util import configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seed: None, Device: None'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.get_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n"
     ]
    }
   ],
   "source": [
    "# print the global variables\n",
    "print(configs.project_seed, configs.project_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During configuration random seed 789 has been set.\n",
      "789 cpu\n"
     ]
    }
   ],
   "source": [
    "configs.set_seed(789)\n",
    "device = configs.set_device(force_cpu=True)\n",
    "\n",
    "# global variables have changed too\n",
    "print(configs.project_seed, configs.project_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seed: 789, Device: cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see if the get function also agrees:\n",
    "configs.get_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the configurations values are assigned globally, we can import the modules. If this is working, we expect each module to access the **same** **seed** and **device** we set. We are also expecting generated numbers **inside the modules** to be reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During configuration random seed 789 has been set.\n",
      "Importing models_util.utility_functions, running in cpu with seed: 789\n"
     ]
    }
   ],
   "source": [
    "# Load home modules and check the device where they are running \n",
    "from models_util import utility_functions as uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During configuration random seed 789 has been set.\n",
      "Importing models_util.custom_dataset, running in cpu with seed: 789\n"
     ]
    }
   ],
   "source": [
    "from models_util import custom_dataset as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During configuration random seed 789 has been set.\n",
      "Importing models_util.cost_functions, running in cpu with seed: 789\n"
     ]
    }
   ],
   "source": [
    "from models_util import cost_functions as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During configuration random seed 789 has been set.\n",
      "Importing models_util.VAE1, running in cpu with seed: 789\n"
     ]
    }
   ],
   "source": [
    "from models_util import VAE1 as v1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCBC Data scale and split for VAE\n",
    "- We will perform min-max scaling to the TMT-Ratios of the proteomic SCBC data. <br>\n",
    "- We will scale the array version of our scbc data, the `npscbc` matrix.\n",
    "- Then we will copy this scaled matrix and reshuffle the copy. The `npscbc_scaled_shuffled` will be used for the model training and performance evaluattion. <br>\n",
    "- The `npscbc_scaled` matrix with the original order of rows will be used later for the validation of the latent variables. <br> \n",
    "- It is important to use the non-missing min and max values of dataset row-by-row <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path and read the scbc data\n",
    "data_path = os.getcwd() + \"\\\\data\\\\processed\\\\\" \n",
    "scbc = pd.read_csv(data_path+\"protein_quant_merged.txt\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(104200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to numpy \n",
    "npscbc = scbc.to_numpy()\n",
    "np.isnan(npscbc).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10439, 1) (10439, 1) 0 0\n"
     ]
    }
   ],
   "source": [
    "# Get extreme values (non-missing) frome ach row. \n",
    "scbc_min = np.nanmin(npscbc, axis=1, keepdims=True)  # minimum among non-NaN\n",
    "scbc_max = np.nanmax(npscbc, axis=1,keepdims=True)  # maximum among non-NaN\n",
    "\n",
    "# check that that shapes and values are as expected \n",
    "print(scbc_max.shape,scbc_min.shape,np.isnan(scbc_max).sum(), np.isnan(scbc_min).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10439, 130)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale data \n",
    "npscbc_scaled = (npscbc - scbc_min) /(scbc_max - scbc_min + 1e-8)\n",
    "npscbc_scaled.shape\n",
    "\n",
    "# npscbc_scaled[0:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the rows but keep scaled original\n",
    "npscbc_scaled_shuffled = npscbc_scaled.copy()\n",
    "np.random.shuffle(npscbc_scaled_shuffled)\n",
    "# npscbc_scaled[1,],scbc.iloc[1,:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7829, 130), (1044, 130), (1566, 130))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = uf.create_data_partition(\n",
    "    npscbc_scaled_shuffled, test_perc=0.15, val=True, val_perc=0.1\n",
    ")\n",
    "train_data.shape, val_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test reproducibility by re-runing the function and checking the data in the first index of the matrix. We expect it to be the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass data to Custom Dataset and DataLoaders \n",
    "- check that your data is numpy matrix.\n",
    "- check if data is scaled to (0,1).\n",
    "- create three custom dataset instances.\n",
    "- the custom dataset will save all the data to memory and create a mask where NaNs are located.\n",
    "- the numpy arrays will be converted to tensors of appropriate dimensions and NaNs to zeroes.\n",
    "- then we pass the custom dataset to the dataloader object.\n",
    "- The DataLoader object contains for each row (training example) i) a tensor of 1 x 130 columns with 0-1 scaled values, ii) a 1x130 mask indicating NA positions and iii) index of the examples per batch (could be 64, 128,..., batch_size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein Dataset is passed to memory\n",
      "No Protein Symbols were identified\n",
      "Protein Dataset is passed to memory\n",
      "No Protein Symbols were identified\n",
      "Protein Dataset is passed to memory\n",
      "No Protein Symbols were identified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = cd.ProteinDataset(train_data)\n",
    "val_dataset = cd.ProteinDataset(val_data)\n",
    "test_dataset = cd.ProteinDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass data to the dataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.3194, 0.3143, 0.7764,  ..., 0.1963, 0.1153, 0.1345],\n",
       "         [0.4190, 0.6575, 0.3335,  ..., 0.4849, 0.3744, 0.3658],\n",
       "         [0.3561, 0.3641, 0.4035,  ..., 0.1131, 0.1191, 0.0636],\n",
       "         ...,\n",
       "         [0.3615, 0.3926, 0.3772,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0655, 0.1453, 0.8225,  ..., 0.3855, 0.4654, 0.5156],\n",
       "         [0.4523, 0.4286, 0.3208,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ...,  True,  True,  True]]),\n",
       " tensor([4390, 6714, 5738, 4680, 1334, 2046, 2663, 3916, 5714, 4224, 3299, 2071,\n",
       "          320, 5564, 1260, 6530, 3223, 7006, 6636, 4399, 3906,  545, 5003,   78,\n",
       "           20, 1961, 3197, 1399,  356, 6002, 3961, 4457, 1233, 7111,  723,   76,\n",
       "         4811, 1646, 5244, 4183,  681, 3920,   68, 7681, 1748, 5841, 4121, 6326,\n",
       "         1332,  589,  943, 1271, 5211, 1641, 5485, 2774, 6068, 4474, 3580,  138,\n",
       "         7757, 2326, 3225, 3073, 7756, 3507, 5785, 6596, 1053, 7445, 3391,  406,\n",
       "         3176,  740, 2965, 5586, 2800, 2982,  607,  501, 5055, 3271, 1662, 6737,\n",
       "         2017,  214, 2137, 6031, 2330, 5505,  944,  776, 5880,  508, 7076, 6774,\n",
       "         4760, 7564, 3382, 3439,   80, 4673, 6050, 5197, 1844, 4083, 6301, 3311,\n",
       "         6643, 2980,  371, 2627, 4300, 4107, 1780, 4859, 2205, 2680, 3839, 5611,\n",
       "         7758, 7505, 5748, 6336, 1688, 4136, 1634, 7391], dtype=torch.int32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the train loader is not reproducible bcs it shuffles but it is not seeded yet. \n",
    "# here is one batch of training examples \n",
    "# torch.manual_seed(888)\n",
    "\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bit optimization Loop \n",
    "It comprises the run of the training and validation set. VAE inherently have a tendency to overfit, so it is important to keep the test set after training loop. In this tutorial we run one model. The name is based on a simple numbering system and its layers to track it down. Furthermore the train_val_loop creates a hyperparameter string to track other parameters. The whole loop is parametrized in a function: <br>\n",
    "- The function starts with a pre-training evaluation to initialize metrics at epoch = 0 <br>\n",
    "- Then training of the model begins and after each epoch, the validation set is passed through the model to get the validation - epoch metrics.<br>\n",
    "\n",
    "\n",
    "During training, these are computed:\n",
    "- KL, Gaussian Logliklihood error, and Total Error are monitored per training batch, and also averaged every n batches.\n",
    "- KL, Gaussian Logliklihood error, and Total Error are monitored per validation round (per epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_0_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86850b2f31e477ab65d8b6dd522283c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 1.390| Val KL: 0.4332916802830166 | Val Rec: 0.956\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 0.691|Train Rec: 0.247 | Val loss: 0.122, Val Rec: 0.106\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 0.139|Train Rec: 0.102 | Val loss: 0.107, Val Rec: 0.102\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 0.099|Train Rec: 0.088 | Val loss: 0.096, Val Rec: 0.093\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 0.087|Train Rec: 0.082 | Val loss: 0.090, Val Rec: 0.088\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 0.078|Train Rec: 0.075 | Val loss: 0.083, Val Rec: 0.081\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 0.075|Train Rec: 0.074 | Val loss: 0.078, Val Rec: 0.076\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 0.071|Train Rec: 0.069 | Val loss: 0.075, Val Rec: 0.073\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 0.068|Train Rec: 0.066 | Val loss: 0.066, Val Rec: 0.065\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 0.065|Train Rec: 0.064 | Val loss: 0.068, Val Rec: 0.066\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 0.064|Train Rec: 0.063 | Val loss: 0.065, Val Rec: 0.064\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 0.062|Train Rec: 0.061 | Val loss: 0.061, Val Rec: 0.059\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 0.061|Train Rec: 0.060 | Val loss: 0.059, Val Rec: 0.058\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 0.058|Train Rec: 0.058 | Val loss: 0.059, Val Rec: 0.059\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 0.059|Train Rec: 0.058 | Val loss: 0.058, Val Rec: 0.058\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 0.057|Train Rec: 0.056 | Val loss: 0.059, Val Rec: 0.059\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 0.055|Train Rec: 0.055 | Val loss: 0.059, Val Rec: 0.058\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 0.055|Train Rec: 0.055 | Val loss: 0.056, Val Rec: 0.056\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 0.055|Train Rec: 0.055 | Val loss: 0.056, Val Rec: 0.056\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 0.055|Train Rec: 0.055 | Val loss: 0.060, Val Rec: 0.059\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 0.054|Train Rec: 0.054 | Val loss: 0.057, Val Rec: 0.056\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 0.054|Train Rec: 0.054 | Val loss: 0.057, Val Rec: 0.057\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 0.054|Train Rec: 0.054 | Val loss: 0.055, Val Rec: 0.055\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.055, Val Rec: 0.055\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.055, Val Rec: 0.055\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.057, Val Rec: 0.057\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 0.054|Train Rec: 0.054 | Val loss: 0.055, Val Rec: 0.055\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 0.054|Train Rec: 0.054 | Val loss: 0.057, Val Rec: 0.057\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 0.055|Train Rec: 0.055 | Val loss: 0.057, Val Rec: 0.057\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.057, Val Rec: 0.057\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.056, Val Rec: 0.056\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.055, Val Rec: 0.055\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.055, Val Rec: 0.055\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.055, Val Rec: 0.055\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 0.054|Train Rec: 0.054 | Val loss: 0.057, Val Rec: 0.057\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.057, Val Rec: 0.057\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.056, Val Rec: 0.056\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.056, Val Rec: 0.056\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.056, Val Rec: 0.056\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.055, Val Rec: 0.055\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 0.053|Train Rec: 0.053 | Val loss: 0.056, Val Rec: 0.056\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_0_75_37\\modelb_0_75_37_ep40_norm0_bits0_bs128_lr0.005.pth\n",
      "Model: modelb_0_75_37_ep40_norm0_bits0_bs128_lr0.005 has been trained\n",
      "Using this model modelb_0_75_37_ep40_norm0_bits0_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_1_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063e082b35314966a13939c661b1e173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 6.094| Val KL: 5.130963113572863 | Val Rec: 0.963\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 5.316|Train Rec: 0.109 | Val loss: 4.987, Val Rec: -0.144\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 4.962|Train Rec: -0.196 | Val loss: 4.877, Val Rec: -0.254\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 4.903|Train Rec: -0.249 | Val loss: 4.845, Val Rec: -0.293\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 4.865|Train Rec: -0.286 | Val loss: 4.830, Val Rec: -0.311\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 4.857|Train Rec: -0.294 | Val loss: 4.830, Val Rec: -0.305\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 4.838|Train Rec: -0.312 | Val loss: 4.861, Val Rec: -0.268\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 4.836|Train Rec: -0.314 | Val loss: 4.842, Val Rec: -0.297\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 4.820|Train Rec: -0.328 | Val loss: 4.815, Val Rec: -0.316\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 4.805|Train Rec: -0.342 | Val loss: 4.804, Val Rec: -0.329\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 4.805|Train Rec: -0.341 | Val loss: 4.788, Val Rec: -0.345\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 4.796|Train Rec: -0.350 | Val loss: 4.793, Val Rec: -0.351\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 4.802|Train Rec: -0.346 | Val loss: 4.782, Val Rec: -0.347\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 4.786|Train Rec: -0.361 | Val loss: 4.765, Val Rec: -0.376\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 4.784|Train Rec: -0.361 | Val loss: 4.804, Val Rec: -0.327\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 4.776|Train Rec: -0.371 | Val loss: 4.784, Val Rec: -0.346\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 4.777|Train Rec: -0.367 | Val loss: 4.754, Val Rec: -0.377\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 4.774|Train Rec: -0.372 | Val loss: 4.745, Val Rec: -0.386\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 4.758|Train Rec: -0.384 | Val loss: 4.768, Val Rec: -0.364\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 4.762|Train Rec: -0.383 | Val loss: 4.746, Val Rec: -0.385\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 4.758|Train Rec: -0.385 | Val loss: 4.752, Val Rec: -0.380\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 4.758|Train Rec: -0.386 | Val loss: 4.772, Val Rec: -0.362\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 4.749|Train Rec: -0.394 | Val loss: 4.754, Val Rec: -0.378\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 4.756|Train Rec: -0.387 | Val loss: 4.742, Val Rec: -0.390\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 4.756|Train Rec: -0.387 | Val loss: 4.736, Val Rec: -0.394\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 4.744|Train Rec: -0.398 | Val loss: 4.736, Val Rec: -0.395\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 4.756|Train Rec: -0.388 | Val loss: 4.732, Val Rec: -0.399\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 4.756|Train Rec: -0.386 | Val loss: 4.777, Val Rec: -0.358\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 4.754|Train Rec: -0.388 | Val loss: 4.725, Val Rec: -0.407\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 4.756|Train Rec: -0.388 | Val loss: 4.723, Val Rec: -0.410\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 4.754|Train Rec: -0.389 | Val loss: 4.736, Val Rec: -0.397\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 4.752|Train Rec: -0.391 | Val loss: 4.740, Val Rec: -0.390\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 4.752|Train Rec: -0.392 | Val loss: 4.732, Val Rec: -0.398\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 4.747|Train Rec: -0.395 | Val loss: 4.741, Val Rec: -0.392\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 4.756|Train Rec: -0.388 | Val loss: 4.740, Val Rec: -0.393\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 4.745|Train Rec: -0.398 | Val loss: 4.744, Val Rec: -0.387\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 4.743|Train Rec: -0.400 | Val loss: 4.735, Val Rec: -0.400\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 4.741|Train Rec: -0.402 | Val loss: 4.742, Val Rec: -0.388\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 4.747|Train Rec: -0.397 | Val loss: 4.741, Val Rec: -0.389\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 4.741|Train Rec: -0.402 | Val loss: 4.717, Val Rec: -0.413\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 4.741|Train Rec: -0.403 | Val loss: 4.736, Val Rec: -0.397\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_1_75_37\\modelb_1_75_37_ep40_norm0_bits0.2_bs128_lr0.005.pth\n",
      "Model: modelb_1_75_37_ep40_norm0_bits0.2_bs128_lr0.005 has been trained\n",
      "Using this model modelb_1_75_37_ep40_norm0_bits0.2_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_2_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f75d593c0f40f0a1cd50fb9b08a02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 11.214| Val KL: 10.25857819451226 | Val Rec: 0.955\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 10.330|Train Rec: 0.027 | Val loss: 10.005, Val Rec: -0.258\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 9.999|Train Rec: -0.285 | Val loss: 9.930, Val Rec: -0.333\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 9.921|Train Rec: -0.359 | Val loss: 9.904, Val Rec: -0.363\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 9.914|Train Rec: -0.366 | Val loss: 9.864, Val Rec: -0.401\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 9.876|Train Rec: -0.404 | Val loss: 9.849, Val Rec: -0.410\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 9.860|Train Rec: -0.419 | Val loss: 9.841, Val Rec: -0.418\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 9.844|Train Rec: -0.433 | Val loss: 9.837, Val Rec: -0.424\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 9.830|Train Rec: -0.449 | Val loss: 9.824, Val Rec: -0.435\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 9.820|Train Rec: -0.456 | Val loss: 9.787, Val Rec: -0.475\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 9.815|Train Rec: -0.464 | Val loss: 9.813, Val Rec: -0.454\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 9.799|Train Rec: -0.478 | Val loss: 9.775, Val Rec: -0.485\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 9.789|Train Rec: -0.487 | Val loss: 9.776, Val Rec: -0.484\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 9.774|Train Rec: -0.501 | Val loss: 9.748, Val Rec: -0.512\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 9.774|Train Rec: -0.503 | Val loss: 9.756, Val Rec: -0.504\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 9.768|Train Rec: -0.506 | Val loss: 9.734, Val Rec: -0.526\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 9.750|Train Rec: -0.524 | Val loss: 9.763, Val Rec: -0.499\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 9.748|Train Rec: -0.527 | Val loss: 9.733, Val Rec: -0.527\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 9.751|Train Rec: -0.525 | Val loss: 9.745, Val Rec: -0.516\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 9.745|Train Rec: -0.530 | Val loss: 9.734, Val Rec: -0.528\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 9.743|Train Rec: -0.533 | Val loss: 9.727, Val Rec: -0.533\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 9.749|Train Rec: -0.527 | Val loss: 9.721, Val Rec: -0.538\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 9.737|Train Rec: -0.538 | Val loss: 9.715, Val Rec: -0.546\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 9.730|Train Rec: -0.546 | Val loss: 9.701, Val Rec: -0.560\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 9.732|Train Rec: -0.544 | Val loss: 9.725, Val Rec: -0.536\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 9.735|Train Rec: -0.540 | Val loss: 9.730, Val Rec: -0.530\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 9.728|Train Rec: -0.548 | Val loss: 9.719, Val Rec: -0.541\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 9.731|Train Rec: -0.545 | Val loss: 9.719, Val Rec: -0.542\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 9.723|Train Rec: -0.553 | Val loss: 9.707, Val Rec: -0.557\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 9.721|Train Rec: -0.552 | Val loss: 9.705, Val Rec: -0.555\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 9.720|Train Rec: -0.554 | Val loss: 9.685, Val Rec: -0.574\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 9.723|Train Rec: -0.552 | Val loss: 9.725, Val Rec: -0.536\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 9.716|Train Rec: -0.558 | Val loss: 9.719, Val Rec: -0.542\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 9.729|Train Rec: -0.548 | Val loss: 9.715, Val Rec: -0.547\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 9.720|Train Rec: -0.554 | Val loss: 9.706, Val Rec: -0.557\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 9.716|Train Rec: -0.559 | Val loss: 9.696, Val Rec: -0.565\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 9.710|Train Rec: -0.564 | Val loss: 9.692, Val Rec: -0.568\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 9.723|Train Rec: -0.554 | Val loss: 9.709, Val Rec: -0.553\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 9.723|Train Rec: -0.552 | Val loss: 9.681, Val Rec: -0.579\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 9.713|Train Rec: -0.561 | Val loss: 9.683, Val Rec: -0.578\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 9.714|Train Rec: -0.561 | Val loss: 9.700, Val Rec: -0.561\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_2_75_37\\modelb_2_75_37_ep40_norm0_bits0.4_bs128_lr0.005.pth\n",
      "Model: modelb_2_75_37_ep40_norm0_bits0.4_bs128_lr0.005 has been trained\n",
      "Using this model modelb_2_75_37_ep40_norm0_bits0.4_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_3_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5afbc61adc84cc5abf062052eeb7790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 16.349| Val KL: 15.387868775261772 | Val Rec: 0.961\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 15.411|Train Rec: -0.009 | Val loss: 15.069, Val Rec: -0.326\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 15.061|Train Rec: -0.349 | Val loss: 14.981, Val Rec: -0.415\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 14.988|Train Rec: -0.423 | Val loss: 15.028, Val Rec: -0.360\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 14.963|Train Rec: -0.446 | Val loss: 14.907, Val Rec: -0.481\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 14.913|Train Rec: -0.496 | Val loss: 14.890, Val Rec: -0.499\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 14.904|Train Rec: -0.505 | Val loss: 14.874, Val Rec: -0.515\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 14.880|Train Rec: -0.527 | Val loss: 14.907, Val Rec: -0.487\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 14.866|Train Rec: -0.541 | Val loss: 14.843, Val Rec: -0.547\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 14.849|Train Rec: -0.558 | Val loss: 14.842, Val Rec: -0.550\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 14.862|Train Rec: -0.546 | Val loss: 14.826, Val Rec: -0.562\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 14.839|Train Rec: -0.568 | Val loss: 14.818, Val Rec: -0.571\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 14.824|Train Rec: -0.581 | Val loss: 14.799, Val Rec: -0.590\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 14.810|Train Rec: -0.594 | Val loss: 14.799, Val Rec: -0.589\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 14.806|Train Rec: -0.599 | Val loss: 14.814, Val Rec: -0.575\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 14.793|Train Rec: -0.611 | Val loss: 14.767, Val Rec: -0.621\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 14.788|Train Rec: -0.614 | Val loss: 14.775, Val Rec: -0.615\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 14.786|Train Rec: -0.618 | Val loss: 14.745, Val Rec: -0.645\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 14.771|Train Rec: -0.633 | Val loss: 14.763, Val Rec: -0.627\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 14.786|Train Rec: -0.618 | Val loss: 14.811, Val Rec: -0.577\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 14.789|Train Rec: -0.614 | Val loss: 14.780, Val Rec: -0.612\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 14.764|Train Rec: -0.639 | Val loss: 14.742, Val Rec: -0.646\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 14.772|Train Rec: -0.630 | Val loss: 14.731, Val Rec: -0.658\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 14.761|Train Rec: -0.643 | Val loss: 14.736, Val Rec: -0.654\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 14.760|Train Rec: -0.643 | Val loss: 14.815, Val Rec: -0.576\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 14.757|Train Rec: -0.646 | Val loss: 14.725, Val Rec: -0.663\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 14.757|Train Rec: -0.645 | Val loss: 14.731, Val Rec: -0.658\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 14.757|Train Rec: -0.645 | Val loss: 14.732, Val Rec: -0.657\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 14.753|Train Rec: -0.650 | Val loss: 14.724, Val Rec: -0.666\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 14.748|Train Rec: -0.654 | Val loss: 14.700, Val Rec: -0.689\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 14.745|Train Rec: -0.658 | Val loss: 14.724, Val Rec: -0.665\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 14.739|Train Rec: -0.663 | Val loss: 14.688, Val Rec: -0.703\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 14.741|Train Rec: -0.662 | Val loss: 14.705, Val Rec: -0.684\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 14.749|Train Rec: -0.654 | Val loss: 14.713, Val Rec: -0.676\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 14.745|Train Rec: -0.658 | Val loss: 14.706, Val Rec: -0.684\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 14.739|Train Rec: -0.665 | Val loss: 14.772, Val Rec: -0.618\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 14.759|Train Rec: -0.646 | Val loss: 14.718, Val Rec: -0.672\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 14.738|Train Rec: -0.664 | Val loss: 14.762, Val Rec: -0.633\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 14.742|Train Rec: -0.661 | Val loss: 14.712, Val Rec: -0.680\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 14.739|Train Rec: -0.663 | Val loss: 14.719, Val Rec: -0.671\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 14.736|Train Rec: -0.667 | Val loss: 14.690, Val Rec: -0.698\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_3_75_37\\modelb_3_75_37_ep40_norm0_bits0.6_bs128_lr0.005.pth\n",
      "Model: modelb_3_75_37_ep40_norm0_bits0.6_bs128_lr0.005 has been trained\n",
      "Using this model modelb_3_75_37_ep40_norm0_bits0.6_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_4_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6011ecff80f44f84a64bc2c8e549b0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 21.472| Val KL: 20.51715638902452 | Val Rec: 0.955\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 20.527|Train Rec: -0.013 | Val loss: 20.163, Val Rec: -0.363\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 20.152|Train Rec: -0.387 | Val loss: 20.115, Val Rec: -0.403\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 20.140|Train Rec: -0.401 | Val loss: 20.138, Val Rec: -0.380\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 20.061|Train Rec: -0.483 | Val loss: 20.019, Val Rec: -0.499\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 20.040|Train Rec: -0.500 | Val loss: 20.002, Val Rec: -0.515\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 20.019|Train Rec: -0.519 | Val loss: 19.946, Val Rec: -0.571\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 19.965|Train Rec: -0.572 | Val loss: 19.972, Val Rec: -0.546\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 19.950|Train Rec: -0.586 | Val loss: 19.915, Val Rec: -0.617\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 19.934|Train Rec: -0.604 | Val loss: 19.919, Val Rec: -0.600\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 19.928|Train Rec: -0.607 | Val loss: 19.917, Val Rec: -0.605\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 19.917|Train Rec: -0.618 | Val loss: 19.861, Val Rec: -0.659\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 19.885|Train Rec: -0.649 | Val loss: 19.870, Val Rec: -0.649\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 19.878|Train Rec: -0.656 | Val loss: 19.902, Val Rec: -0.617\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 19.876|Train Rec: -0.656 | Val loss: 19.833, Val Rec: -0.685\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 19.862|Train Rec: -0.672 | Val loss: 19.842, Val Rec: -0.677\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 19.850|Train Rec: -0.682 | Val loss: 19.842, Val Rec: -0.676\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 19.847|Train Rec: -0.685 | Val loss: 19.822, Val Rec: -0.696\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 19.849|Train Rec: -0.682 | Val loss: 19.828, Val Rec: -0.690\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 19.834|Train Rec: -0.698 | Val loss: 19.831, Val Rec: -0.688\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 19.829|Train Rec: -0.701 | Val loss: 19.813, Val Rec: -0.706\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 19.820|Train Rec: -0.710 | Val loss: 19.808, Val Rec: -0.710\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 19.829|Train Rec: -0.701 | Val loss: 19.804, Val Rec: -0.716\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 19.816|Train Rec: -0.713 | Val loss: 19.785, Val Rec: -0.734\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 19.826|Train Rec: -0.705 | Val loss: 19.835, Val Rec: -0.684\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 19.820|Train Rec: -0.710 | Val loss: 19.778, Val Rec: -0.740\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 19.812|Train Rec: -0.718 | Val loss: 19.792, Val Rec: -0.729\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 19.810|Train Rec: -0.720 | Val loss: 19.761, Val Rec: -0.758\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 19.810|Train Rec: -0.721 | Val loss: 19.780, Val Rec: -0.741\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 19.808|Train Rec: -0.722 | Val loss: 19.748, Val Rec: -0.770\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 19.813|Train Rec: -0.720 | Val loss: 19.821, Val Rec: -0.699\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 19.810|Train Rec: -0.719 | Val loss: 19.749, Val Rec: -0.769\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 19.800|Train Rec: -0.731 | Val loss: 19.784, Val Rec: -0.734\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 19.804|Train Rec: -0.726 | Val loss: 19.746, Val Rec: -0.774\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 19.802|Train Rec: -0.727 | Val loss: 19.741, Val Rec: -0.777\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 19.803|Train Rec: -0.728 | Val loss: 19.755, Val Rec: -0.763\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 19.797|Train Rec: -0.733 | Val loss: 19.767, Val Rec: -0.751\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 19.794|Train Rec: -0.737 | Val loss: 19.766, Val Rec: -0.754\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 19.811|Train Rec: -0.719 | Val loss: 19.814, Val Rec: -0.705\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 19.806|Train Rec: -0.725 | Val loss: 19.747, Val Rec: -0.771\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 19.796|Train Rec: -0.733 | Val loss: 19.755, Val Rec: -0.763\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_4_75_37\\modelb_4_75_37_ep40_norm0_bits0.8_bs128_lr0.005.pth\n",
      "Model: modelb_4_75_37_ep40_norm0_bits0.8_bs128_lr0.005 has been trained\n",
      "Using this model modelb_4_75_37_ep40_norm0_bits0.8_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_5_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a452d7e415469f9d0039f1cc6ce0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 26.602| Val KL: 25.64645004272461 | Val Rec: 0.955\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 25.614|Train Rec: -0.054 | Val loss: 25.242, Val Rec: -0.419\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 25.251|Train Rec: -0.417 | Val loss: 25.140, Val Rec: -0.511\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 25.146|Train Rec: -0.522 | Val loss: 25.129, Val Rec: -0.518\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 25.118|Train Rec: -0.550 | Val loss: 25.061, Val Rec: -0.586\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 25.096|Train Rec: -0.571 | Val loss: 25.085, Val Rec: -0.561\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 25.055|Train Rec: -0.612 | Val loss: 25.036, Val Rec: -0.613\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 25.047|Train Rec: -0.621 | Val loss: 25.012, Val Rec: -0.636\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 25.047|Train Rec: -0.618 | Val loss: 24.991, Val Rec: -0.656\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 25.000|Train Rec: -0.665 | Val loss: 24.979, Val Rec: -0.669\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 25.004|Train Rec: -0.664 | Val loss: 24.980, Val Rec: -0.668\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 25.014|Train Rec: -0.649 | Val loss: 24.942, Val Rec: -0.705\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 24.973|Train Rec: -0.692 | Val loss: 24.963, Val Rec: -0.684\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 24.959|Train Rec: -0.701 | Val loss: 24.922, Val Rec: -0.725\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 24.942|Train Rec: -0.719 | Val loss: 24.898, Val Rec: -0.749\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 24.934|Train Rec: -0.725 | Val loss: 24.917, Val Rec: -0.730\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 24.927|Train Rec: -0.731 | Val loss: 24.897, Val Rec: -0.751\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 24.921|Train Rec: -0.739 | Val loss: 24.898, Val Rec: -0.750\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 24.917|Train Rec: -0.741 | Val loss: 24.896, Val Rec: -0.751\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 24.914|Train Rec: -0.744 | Val loss: 24.886, Val Rec: -0.762\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 24.907|Train Rec: -0.751 | Val loss: 24.859, Val Rec: -0.788\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 24.902|Train Rec: -0.755 | Val loss: 24.863, Val Rec: -0.785\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 24.893|Train Rec: -0.765 | Val loss: 24.865, Val Rec: -0.784\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 24.903|Train Rec: -0.756 | Val loss: 24.880, Val Rec: -0.768\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 24.897|Train Rec: -0.760 | Val loss: 24.862, Val Rec: -0.786\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 24.897|Train Rec: -0.762 | Val loss: 24.841, Val Rec: -0.807\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 24.893|Train Rec: -0.764 | Val loss: 24.845, Val Rec: -0.803\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 24.899|Train Rec: -0.762 | Val loss: 24.840, Val Rec: -0.807\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 24.907|Train Rec: -0.749 | Val loss: 24.877, Val Rec: -0.771\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 24.895|Train Rec: -0.763 | Val loss: 24.839, Val Rec: -0.809\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 24.879|Train Rec: -0.778 | Val loss: 24.845, Val Rec: -0.803\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 24.876|Train Rec: -0.781 | Val loss: 24.828, Val Rec: -0.819\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 24.877|Train Rec: -0.780 | Val loss: 24.825, Val Rec: -0.823\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 24.874|Train Rec: -0.783 | Val loss: 24.843, Val Rec: -0.806\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 24.878|Train Rec: -0.778 | Val loss: 24.825, Val Rec: -0.821\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 24.872|Train Rec: -0.785 | Val loss: 24.835, Val Rec: -0.814\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 24.876|Train Rec: -0.781 | Val loss: 24.830, Val Rec: -0.821\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 24.868|Train Rec: -0.789 | Val loss: 24.826, Val Rec: -0.821\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 24.864|Train Rec: -0.793 | Val loss: 24.802, Val Rec: -0.846\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 24.864|Train Rec: -0.794 | Val loss: 24.811, Val Rec: -0.836\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 24.869|Train Rec: -0.788 | Val loss: 24.820, Val Rec: -0.827\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_5_75_37\\modelb_5_75_37_ep40_norm0_bits1.0_bs128_lr0.005.pth\n",
      "Model: modelb_5_75_37_ep40_norm0_bits1.0_bs128_lr0.005 has been trained\n",
      "Using this model modelb_5_75_37_ep40_norm0_bits1.0_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_6_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d5e75c22cf469da3ede4785a44030d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 31.720| Val KL: 30.775737550523544 | Val Rec: 0.944\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 30.716|Train Rec: -0.080 | Val loss: 30.351, Val Rec: -0.426\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 30.341|Train Rec: -0.457 | Val loss: 30.244, Val Rec: -0.533\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 30.245|Train Rec: -0.554 | Val loss: 30.218, Val Rec: -0.558\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 30.209|Train Rec: -0.588 | Val loss: 30.181, Val Rec: -0.595\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 30.174|Train Rec: -0.623 | Val loss: 30.172, Val Rec: -0.611\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 30.153|Train Rec: -0.644 | Val loss: 30.159, Val Rec: -0.618\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 30.132|Train Rec: -0.662 | Val loss: 30.124, Val Rec: -0.653\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 30.119|Train Rec: -0.675 | Val loss: 30.078, Val Rec: -0.699\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 30.094|Train Rec: -0.699 | Val loss: 30.081, Val Rec: -0.696\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 30.088|Train Rec: -0.702 | Val loss: 30.097, Val Rec: -0.680\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 30.070|Train Rec: -0.722 | Val loss: 30.069, Val Rec: -0.707\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 30.063|Train Rec: -0.727 | Val loss: 30.011, Val Rec: -0.768\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 30.052|Train Rec: -0.739 | Val loss: 30.072, Val Rec: -0.704\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 30.047|Train Rec: -0.743 | Val loss: 29.995, Val Rec: -0.783\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 30.051|Train Rec: -0.739 | Val loss: 30.014, Val Rec: -0.763\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 30.046|Train Rec: -0.741 | Val loss: 30.052, Val Rec: -0.724\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 30.026|Train Rec: -0.762 | Val loss: 29.994, Val Rec: -0.782\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 30.023|Train Rec: -0.765 | Val loss: 30.004, Val Rec: -0.772\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 30.021|Train Rec: -0.766 | Val loss: 29.987, Val Rec: -0.790\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 30.009|Train Rec: -0.778 | Val loss: 29.977, Val Rec: -0.800\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 29.995|Train Rec: -0.792 | Val loss: 29.974, Val Rec: -0.803\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 30.006|Train Rec: -0.780 | Val loss: 29.945, Val Rec: -0.833\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 29.997|Train Rec: -0.790 | Val loss: 29.946, Val Rec: -0.831\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 29.991|Train Rec: -0.794 | Val loss: 29.951, Val Rec: -0.826\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 29.979|Train Rec: -0.806 | Val loss: 29.934, Val Rec: -0.843\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 29.983|Train Rec: -0.804 | Val loss: 29.976, Val Rec: -0.801\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 29.991|Train Rec: -0.794 | Val loss: 29.943, Val Rec: -0.834\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 29.991|Train Rec: -0.795 | Val loss: 30.041, Val Rec: -0.736\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 29.975|Train Rec: -0.810 | Val loss: 29.965, Val Rec: -0.811\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 29.977|Train Rec: -0.809 | Val loss: 29.917, Val Rec: -0.862\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 29.978|Train Rec: -0.808 | Val loss: 29.967, Val Rec: -0.809\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 29.988|Train Rec: -0.797 | Val loss: 29.955, Val Rec: -0.821\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 29.976|Train Rec: -0.809 | Val loss: 29.945, Val Rec: -0.832\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 29.976|Train Rec: -0.810 | Val loss: 29.911, Val Rec: -0.865\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 29.971|Train Rec: -0.813 | Val loss: 29.994, Val Rec: -0.783\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 29.964|Train Rec: -0.822 | Val loss: 29.937, Val Rec: -0.839\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 29.969|Train Rec: -0.816 | Val loss: 29.908, Val Rec: -0.869\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 29.970|Train Rec: -0.815 | Val loss: 29.949, Val Rec: -0.827\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 29.969|Train Rec: -0.815 | Val loss: 29.893, Val Rec: -0.883\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 29.961|Train Rec: -0.823 | Val loss: 29.882, Val Rec: -0.894\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_6_75_37\\modelb_6_75_37_ep40_norm0_bits1.2_bs128_lr0.005.pth\n",
      "Model: modelb_6_75_37_ep40_norm0_bits1.2_bs128_lr0.005 has been trained\n",
      "Using this model modelb_6_75_37_ep40_norm0_bits1.2_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_7_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00a2ef2c3ba480d9c8386cd3a0d3cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 36.862| Val KL: 35.905025482177734 | Val Rec: 0.957\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 35.826|Train Rec: -0.100 | Val loss: 35.497, Val Rec: -0.408\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 35.452|Train Rec: -0.476 | Val loss: 35.357, Val Rec: -0.548\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 35.344|Train Rec: -0.580 | Val loss: 35.297, Val Rec: -0.608\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 35.315|Train Rec: -0.609 | Val loss: 35.307, Val Rec: -0.600\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 35.269|Train Rec: -0.653 | Val loss: 35.210, Val Rec: -0.701\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 35.276|Train Rec: -0.650 | Val loss: 35.228, Val Rec: -0.684\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 35.232|Train Rec: -0.689 | Val loss: 35.219, Val Rec: -0.686\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 35.220|Train Rec: -0.701 | Val loss: 35.169, Val Rec: -0.737\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 35.190|Train Rec: -0.730 | Val loss: 35.153, Val Rec: -0.753\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 35.179|Train Rec: -0.741 | Val loss: 35.165, Val Rec: -0.741\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 35.170|Train Rec: -0.749 | Val loss: 35.148, Val Rec: -0.759\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 35.151|Train Rec: -0.767 | Val loss: 35.124, Val Rec: -0.783\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 35.160|Train Rec: -0.758 | Val loss: 35.131, Val Rec: -0.775\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 35.158|Train Rec: -0.761 | Val loss: 35.174, Val Rec: -0.731\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 35.154|Train Rec: -0.763 | Val loss: 35.132, Val Rec: -0.774\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 35.131|Train Rec: -0.784 | Val loss: 35.101, Val Rec: -0.805\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 35.118|Train Rec: -0.797 | Val loss: 35.091, Val Rec: -0.814\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 35.119|Train Rec: -0.796 | Val loss: 35.096, Val Rec: -0.810\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 35.114|Train Rec: -0.801 | Val loss: 35.082, Val Rec: -0.825\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 35.104|Train Rec: -0.810 | Val loss: 35.068, Val Rec: -0.840\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 35.096|Train Rec: -0.818 | Val loss: 35.081, Val Rec: -0.824\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 35.099|Train Rec: -0.814 | Val loss: 35.047, Val Rec: -0.859\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 35.094|Train Rec: -0.821 | Val loss: 35.067, Val Rec: -0.838\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 35.099|Train Rec: -0.814 | Val loss: 35.054, Val Rec: -0.851\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 35.092|Train Rec: -0.821 | Val loss: 35.092, Val Rec: -0.814\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 35.100|Train Rec: -0.813 | Val loss: 35.071, Val Rec: -0.834\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 35.098|Train Rec: -0.815 | Val loss: 35.107, Val Rec: -0.799\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 35.092|Train Rec: -0.820 | Val loss: 35.048, Val Rec: -0.857\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 35.091|Train Rec: -0.823 | Val loss: 35.056, Val Rec: -0.849\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 35.072|Train Rec: -0.841 | Val loss: 35.045, Val Rec: -0.861\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 35.075|Train Rec: -0.837 | Val loss: 35.049, Val Rec: -0.857\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 35.066|Train Rec: -0.846 | Val loss: 35.026, Val Rec: -0.880\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 35.071|Train Rec: -0.841 | Val loss: 35.012, Val Rec: -0.894\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 35.072|Train Rec: -0.840 | Val loss: 34.996, Val Rec: -0.910\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 35.068|Train Rec: -0.846 | Val loss: 35.033, Val Rec: -0.872\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 35.082|Train Rec: -0.830 | Val loss: 35.005, Val Rec: -0.900\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 35.069|Train Rec: -0.844 | Val loss: 34.994, Val Rec: -0.911\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 35.065|Train Rec: -0.848 | Val loss: 35.011, Val Rec: -0.895\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 35.068|Train Rec: -0.845 | Val loss: 35.006, Val Rec: -0.899\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 35.062|Train Rec: -0.850 | Val loss: 35.009, Val Rec: -0.896\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_7_75_37\\modelb_7_75_37_ep40_norm0_bits1.4_bs128_lr0.005.pth\n",
      "Model: modelb_7_75_37_ep40_norm0_bits1.4_bs128_lr0.005 has been trained\n",
      "Using this model modelb_7_75_37_ep40_norm0_bits1.4_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_8_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce44cc418ede406ea1ded0eec32bddb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 41.988| Val KL: 41.03431277804904 | Val Rec: 0.953\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 40.945|Train Rec: -0.105 | Val loss: 40.606, Val Rec: -0.436\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 40.569|Train Rec: -0.483 | Val loss: 40.511, Val Rec: -0.524\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 40.473|Train Rec: -0.582 | Val loss: 40.437, Val Rec: -0.598\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 40.431|Train Rec: -0.628 | Val loss: 40.419, Val Rec: -0.618\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 40.436|Train Rec: -0.616 | Val loss: 40.319, Val Rec: -0.716\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 40.357|Train Rec: -0.696 | Val loss: 40.344, Val Rec: -0.690\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 40.350|Train Rec: -0.700 | Val loss: 40.303, Val Rec: -0.731\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 40.305|Train Rec: -0.743 | Val loss: 40.295, Val Rec: -0.739\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 40.314|Train Rec: -0.735 | Val loss: 40.267, Val Rec: -0.767\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 40.288|Train Rec: -0.758 | Val loss: 40.239, Val Rec: -0.797\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 40.276|Train Rec: -0.773 | Val loss: 40.265, Val Rec: -0.770\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 40.278|Train Rec: -0.767 | Val loss: 40.254, Val Rec: -0.780\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 40.260|Train Rec: -0.786 | Val loss: 40.269, Val Rec: -0.767\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 40.242|Train Rec: -0.803 | Val loss: 40.216, Val Rec: -0.820\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 40.250|Train Rec: -0.796 | Val loss: 40.198, Val Rec: -0.837\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 40.238|Train Rec: -0.806 | Val loss: 40.219, Val Rec: -0.816\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 40.245|Train Rec: -0.800 | Val loss: 40.220, Val Rec: -0.815\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 40.221|Train Rec: -0.822 | Val loss: 40.212, Val Rec: -0.823\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 40.220|Train Rec: -0.824 | Val loss: 40.220, Val Rec: -0.815\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 40.229|Train Rec: -0.815 | Val loss: 40.216, Val Rec: -0.819\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 40.203|Train Rec: -0.840 | Val loss: 40.208, Val Rec: -0.826\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 40.215|Train Rec: -0.827 | Val loss: 40.181, Val Rec: -0.855\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 40.206|Train Rec: -0.836 | Val loss: 40.242, Val Rec: -0.793\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 40.213|Train Rec: -0.829 | Val loss: 40.166, Val Rec: -0.869\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 40.221|Train Rec: -0.821 | Val loss: 40.201, Val Rec: -0.834\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 40.193|Train Rec: -0.849 | Val loss: 40.167, Val Rec: -0.867\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 40.180|Train Rec: -0.861 | Val loss: 40.179, Val Rec: -0.855\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 40.185|Train Rec: -0.857 | Val loss: 40.148, Val Rec: -0.886\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 40.183|Train Rec: -0.858 | Val loss: 40.138, Val Rec: -0.896\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 40.177|Train Rec: -0.864 | Val loss: 40.115, Val Rec: -0.920\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 40.179|Train Rec: -0.861 | Val loss: 40.128, Val Rec: -0.907\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 40.183|Train Rec: -0.858 | Val loss: 40.138, Val Rec: -0.897\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 40.178|Train Rec: -0.863 | Val loss: 40.112, Val Rec: -0.923\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 40.171|Train Rec: -0.870 | Val loss: 40.153, Val Rec: -0.882\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 40.174|Train Rec: -0.866 | Val loss: 40.120, Val Rec: -0.915\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 40.170|Train Rec: -0.870 | Val loss: 40.117, Val Rec: -0.918\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 40.174|Train Rec: -0.868 | Val loss: 40.118, Val Rec: -0.917\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 40.167|Train Rec: -0.874 | Val loss: 40.120, Val Rec: -0.916\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 40.171|Train Rec: -0.870 | Val loss: 40.127, Val Rec: -0.909\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 40.158|Train Rec: -0.883 | Val loss: 40.112, Val Rec: -0.923\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_8_75_37\\modelb_8_75_37_ep40_norm0_bits1.6_bs128_lr0.005.pth\n",
      "Model: modelb_8_75_37_ep40_norm0_bits1.6_bs128_lr0.005 has been trained\n",
      "Using this model modelb_8_75_37_ep40_norm0_bits1.6_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_9_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5c97487517435fbed60071549669dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 47.118| Val KL: 46.163604736328125 | Val Rec: 0.955\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 46.080|Train Rec: -0.102 | Val loss: 45.796, Val Rec: -0.371\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 45.685|Train Rec: -0.494 | Val loss: 45.562, Val Rec: -0.602\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 45.564|Train Rec: -0.617 | Val loss: 45.495, Val Rec: -0.669\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 45.504|Train Rec: -0.678 | Val loss: 45.467, Val Rec: -0.698\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 45.481|Train Rec: -0.700 | Val loss: 45.514, Val Rec: -0.650\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 45.463|Train Rec: -0.715 | Val loss: 45.485, Val Rec: -0.679\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 45.428|Train Rec: -0.749 | Val loss: 45.484, Val Rec: -0.680\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 45.431|Train Rec: -0.746 | Val loss: 45.388, Val Rec: -0.776\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 45.411|Train Rec: -0.767 | Val loss: 45.464, Val Rec: -0.701\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 45.462|Train Rec: -0.718 | Val loss: 45.380, Val Rec: -0.783\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 45.423|Train Rec: -0.753 | Val loss: 45.394, Val Rec: -0.771\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 45.386|Train Rec: -0.791 | Val loss: 45.349, Val Rec: -0.815\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 45.381|Train Rec: -0.795 | Val loss: 45.405, Val Rec: -0.758\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 45.362|Train Rec: -0.813 | Val loss: 45.348, Val Rec: -0.816\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 45.350|Train Rec: -0.824 | Val loss: 45.307, Val Rec: -0.857\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 45.339|Train Rec: -0.833 | Val loss: 45.312, Val Rec: -0.852\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 45.340|Train Rec: -0.832 | Val loss: 45.298, Val Rec: -0.867\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 45.333|Train Rec: -0.839 | Val loss: 45.357, Val Rec: -0.807\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 45.325|Train Rec: -0.847 | Val loss: 45.306, Val Rec: -0.858\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 45.327|Train Rec: -0.845 | Val loss: 45.324, Val Rec: -0.840\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 45.324|Train Rec: -0.847 | Val loss: 45.287, Val Rec: -0.877\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 45.329|Train Rec: -0.842 | Val loss: 45.270, Val Rec: -0.894\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 45.330|Train Rec: -0.841 | Val loss: 45.291, Val Rec: -0.873\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 45.311|Train Rec: -0.860 | Val loss: 45.273, Val Rec: -0.890\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 45.312|Train Rec: -0.859 | Val loss: 45.290, Val Rec: -0.874\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 45.320|Train Rec: -0.850 | Val loss: 45.330, Val Rec: -0.834\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 45.295|Train Rec: -0.875 | Val loss: 45.263, Val Rec: -0.902\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 45.295|Train Rec: -0.874 | Val loss: 45.282, Val Rec: -0.882\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 45.300|Train Rec: -0.870 | Val loss: 45.311, Val Rec: -0.854\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 45.297|Train Rec: -0.873 | Val loss: 45.291, Val Rec: -0.874\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 45.287|Train Rec: -0.883 | Val loss: 45.304, Val Rec: -0.861\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 45.281|Train Rec: -0.889 | Val loss: 45.282, Val Rec: -0.882\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 45.289|Train Rec: -0.881 | Val loss: 45.257, Val Rec: -0.909\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 45.283|Train Rec: -0.887 | Val loss: 45.275, Val Rec: -0.889\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 45.275|Train Rec: -0.894 | Val loss: 45.242, Val Rec: -0.923\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 45.273|Train Rec: -0.898 | Val loss: 45.255, Val Rec: -0.909\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 45.273|Train Rec: -0.896 | Val loss: 45.248, Val Rec: -0.916\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 45.276|Train Rec: -0.894 | Val loss: 45.263, Val Rec: -0.902\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 45.273|Train Rec: -0.898 | Val loss: 45.235, Val Rec: -0.928\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 45.284|Train Rec: -0.886 | Val loss: 45.217, Val Rec: -0.947\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_9_75_37\\modelb_9_75_37_ep40_norm0_bits1.8_bs128_lr0.005.pth\n",
      "Model: modelb_9_75_37_ep40_norm0_bits1.8_bs128_lr0.005 has been trained\n",
      "Using this model modelb_9_75_37_ep40_norm0_bits1.8_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_10_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bf1633f38242d18ede285bbf555ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 52.260| Val KL: 51.29290008544922 | Val Rec: 0.967\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 51.178|Train Rec: -0.130 | Val loss: 50.799, Val Rec: -0.503\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 50.769|Train Rec: -0.543 | Val loss: 50.777, Val Rec: -0.516\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 50.669|Train Rec: -0.642 | Val loss: 50.634, Val Rec: -0.660\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 50.617|Train Rec: -0.692 | Val loss: 50.615, Val Rec: -0.679\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 50.593|Train Rec: -0.716 | Val loss: 50.590, Val Rec: -0.705\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 50.597|Train Rec: -0.711 | Val loss: 50.519, Val Rec: -0.775\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 50.540|Train Rec: -0.766 | Val loss: 50.506, Val Rec: -0.787\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 50.523|Train Rec: -0.782 | Val loss: 50.546, Val Rec: -0.748\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 50.507|Train Rec: -0.798 | Val loss: 50.521, Val Rec: -0.773\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 50.501|Train Rec: -0.803 | Val loss: 50.485, Val Rec: -0.808\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 50.499|Train Rec: -0.804 | Val loss: 50.478, Val Rec: -0.815\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 50.486|Train Rec: -0.816 | Val loss: 50.458, Val Rec: -0.836\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 50.469|Train Rec: -0.834 | Val loss: 50.457, Val Rec: -0.837\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 50.473|Train Rec: -0.829 | Val loss: 50.461, Val Rec: -0.832\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 50.462|Train Rec: -0.839 | Val loss: 50.454, Val Rec: -0.839\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 50.477|Train Rec: -0.825 | Val loss: 50.422, Val Rec: -0.871\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 50.448|Train Rec: -0.853 | Val loss: 50.418, Val Rec: -0.875\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 50.448|Train Rec: -0.853 | Val loss: 50.447, Val Rec: -0.846\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 50.439|Train Rec: -0.862 | Val loss: 50.495, Val Rec: -0.798\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 50.453|Train Rec: -0.847 | Val loss: 50.425, Val Rec: -0.868\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 50.432|Train Rec: -0.867 | Val loss: 50.428, Val Rec: -0.865\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 50.434|Train Rec: -0.868 | Val loss: 50.447, Val Rec: -0.846\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 50.456|Train Rec: -0.843 | Val loss: 50.399, Val Rec: -0.894\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 50.417|Train Rec: -0.882 | Val loss: 50.377, Val Rec: -0.916\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 50.428|Train Rec: -0.871 | Val loss: 50.424, Val Rec: -0.869\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 50.413|Train Rec: -0.885 | Val loss: 50.349, Val Rec: -0.944\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 50.414|Train Rec: -0.885 | Val loss: 50.380, Val Rec: -0.913\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 50.430|Train Rec: -0.870 | Val loss: 50.359, Val Rec: -0.934\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 50.430|Train Rec: -0.869 | Val loss: 50.379, Val Rec: -0.914\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 50.412|Train Rec: -0.887 | Val loss: 50.355, Val Rec: -0.938\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 50.417|Train Rec: -0.883 | Val loss: 50.388, Val Rec: -0.906\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 50.406|Train Rec: -0.892 | Val loss: 50.384, Val Rec: -0.909\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 50.406|Train Rec: -0.892 | Val loss: 50.353, Val Rec: -0.940\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 50.411|Train Rec: -0.887 | Val loss: 50.319, Val Rec: -0.974\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 50.390|Train Rec: -0.908 | Val loss: 50.318, Val Rec: -0.976\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 50.397|Train Rec: -0.901 | Val loss: 50.327, Val Rec: -0.966\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 50.387|Train Rec: -0.911 | Val loss: 50.339, Val Rec: -0.954\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 50.398|Train Rec: -0.901 | Val loss: 50.320, Val Rec: -0.973\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 50.396|Train Rec: -0.902 | Val loss: 50.321, Val Rec: -0.972\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 50.391|Train Rec: -0.907 | Val loss: 50.311, Val Rec: -0.983\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_10_75_37\\modelb_10_75_37_ep40_norm0_bits2.0_bs128_lr0.005.pth\n",
      "Model: modelb_10_75_37_ep40_norm0_bits2.0_bs128_lr0.005 has been trained\n",
      "Using this model modelb_10_75_37_ep40_norm0_bits2.0_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_11_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c760791e37d4439abdb3203c4a2f78fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 57.387| Val KL: 56.42217593722873 | Val Rec: 0.965\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 56.288|Train Rec: -0.151 | Val loss: 55.945, Val Rec: -0.477\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 55.865|Train Rec: -0.573 | Val loss: 55.738, Val Rec: -0.685\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 55.769|Train Rec: -0.669 | Val loss: 55.729, Val Rec: -0.695\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 55.714|Train Rec: -0.722 | Val loss: 55.678, Val Rec: -0.745\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 55.685|Train Rec: -0.752 | Val loss: 55.685, Val Rec: -0.738\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 55.654|Train Rec: -0.781 | Val loss: 55.640, Val Rec: -0.783\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 55.642|Train Rec: -0.792 | Val loss: 55.685, Val Rec: -0.737\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 55.624|Train Rec: -0.808 | Val loss: 55.639, Val Rec: -0.783\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 55.626|Train Rec: -0.807 | Val loss: 55.603, Val Rec: -0.820\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 55.600|Train Rec: -0.833 | Val loss: 55.546, Val Rec: -0.877\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 55.619|Train Rec: -0.813 | Val loss: 55.618, Val Rec: -0.805\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 55.598|Train Rec: -0.834 | Val loss: 55.606, Val Rec: -0.816\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 55.591|Train Rec: -0.840 | Val loss: 55.600, Val Rec: -0.822\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 55.578|Train Rec: -0.853 | Val loss: 55.551, Val Rec: -0.871\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 55.585|Train Rec: -0.846 | Val loss: 55.558, Val Rec: -0.865\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 55.565|Train Rec: -0.866 | Val loss: 55.530, Val Rec: -0.893\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 55.554|Train Rec: -0.875 | Val loss: 55.498, Val Rec: -0.925\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 55.555|Train Rec: -0.874 | Val loss: 55.520, Val Rec: -0.903\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 55.552|Train Rec: -0.877 | Val loss: 55.549, Val Rec: -0.874\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 55.545|Train Rec: -0.885 | Val loss: 55.572, Val Rec: -0.851\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 55.546|Train Rec: -0.883 | Val loss: 55.533, Val Rec: -0.890\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 55.536|Train Rec: -0.893 | Val loss: 55.514, Val Rec: -0.908\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 55.539|Train Rec: -0.889 | Val loss: 55.474, Val Rec: -0.949\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 55.532|Train Rec: -0.897 | Val loss: 55.494, Val Rec: -0.929\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 55.534|Train Rec: -0.895 | Val loss: 55.497, Val Rec: -0.926\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 55.519|Train Rec: -0.909 | Val loss: 55.506, Val Rec: -0.917\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 55.514|Train Rec: -0.914 | Val loss: 55.507, Val Rec: -0.915\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 55.517|Train Rec: -0.912 | Val loss: 55.467, Val Rec: -0.956\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 55.519|Train Rec: -0.909 | Val loss: 55.478, Val Rec: -0.945\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 55.510|Train Rec: -0.918 | Val loss: 55.447, Val Rec: -0.975\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 55.516|Train Rec: -0.912 | Val loss: 55.456, Val Rec: -0.967\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 55.529|Train Rec: -0.899 | Val loss: 55.467, Val Rec: -0.955\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 55.524|Train Rec: -0.903 | Val loss: 55.470, Val Rec: -0.952\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 55.527|Train Rec: -0.902 | Val loss: 55.471, Val Rec: -0.951\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 55.556|Train Rec: -0.871 | Val loss: 55.440, Val Rec: -0.983\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 55.505|Train Rec: -0.922 | Val loss: 55.434, Val Rec: -0.989\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 55.492|Train Rec: -0.935 | Val loss: 55.437, Val Rec: -0.985\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 55.504|Train Rec: -0.924 | Val loss: 55.451, Val Rec: -0.972\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 55.507|Train Rec: -0.920 | Val loss: 55.418, Val Rec: -1.007\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 55.512|Train Rec: -0.916 | Val loss: 55.416, Val Rec: -1.006\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_11_75_37\\modelb_11_75_37_ep40_norm0_bits2.2_bs128_lr0.005.pth\n",
      "Model: modelb_11_75_37_ep40_norm0_bits2.2_bs128_lr0.005 has been trained\n",
      "Using this model modelb_11_75_37_ep40_norm0_bits2.2_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_12_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ed145f86894bbea9a5e3b0b19ba061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 62.515| Val KL: 61.55147510104709 | Val Rec: 0.964\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 61.409|Train Rec: -0.159 | Val loss: 61.003, Val Rec: -0.549\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 60.983|Train Rec: -0.588 | Val loss: 60.915, Val Rec: -0.637\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 60.906|Train Rec: -0.660 | Val loss: 60.832, Val Rec: -0.720\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 60.837|Train Rec: -0.732 | Val loss: 60.812, Val Rec: -0.739\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 60.829|Train Rec: -0.735 | Val loss: 60.779, Val Rec: -0.772\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 60.791|Train Rec: -0.772 | Val loss: 60.837, Val Rec: -0.715\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 60.775|Train Rec: -0.788 | Val loss: 60.778, Val Rec: -0.774\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 60.757|Train Rec: -0.805 | Val loss: 60.725, Val Rec: -0.827\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 60.741|Train Rec: -0.821 | Val loss: 60.704, Val Rec: -0.849\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 60.747|Train Rec: -0.815 | Val loss: 60.761, Val Rec: -0.791\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 60.736|Train Rec: -0.825 | Val loss: 60.698, Val Rec: -0.854\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 60.733|Train Rec: -0.828 | Val loss: 60.700, Val Rec: -0.852\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 60.726|Train Rec: -0.835 | Val loss: 60.699, Val Rec: -0.853\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 60.731|Train Rec: -0.828 | Val loss: 60.705, Val Rec: -0.847\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 60.696|Train Rec: -0.862 | Val loss: 60.666, Val Rec: -0.886\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 60.681|Train Rec: -0.877 | Val loss: 60.727, Val Rec: -0.825\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 60.678|Train Rec: -0.881 | Val loss: 60.642, Val Rec: -0.910\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 60.678|Train Rec: -0.880 | Val loss: 60.698, Val Rec: -0.854\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 60.674|Train Rec: -0.884 | Val loss: 60.624, Val Rec: -0.928\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 60.674|Train Rec: -0.883 | Val loss: 60.668, Val Rec: -0.883\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 60.663|Train Rec: -0.894 | Val loss: 60.645, Val Rec: -0.907\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 60.650|Train Rec: -0.907 | Val loss: 60.594, Val Rec: -0.958\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 60.650|Train Rec: -0.907 | Val loss: 60.628, Val Rec: -0.923\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 60.654|Train Rec: -0.903 | Val loss: 60.638, Val Rec: -0.913\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 60.652|Train Rec: -0.905 | Val loss: 60.680, Val Rec: -0.871\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 60.651|Train Rec: -0.906 | Val loss: 60.644, Val Rec: -0.909\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 60.633|Train Rec: -0.923 | Val loss: 60.603, Val Rec: -0.948\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 60.631|Train Rec: -0.925 | Val loss: 60.609, Val Rec: -0.943\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 60.630|Train Rec: -0.926 | Val loss: 60.639, Val Rec: -0.913\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 60.625|Train Rec: -0.932 | Val loss: 60.588, Val Rec: -0.964\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 60.622|Train Rec: -0.934 | Val loss: 60.550, Val Rec: -1.001\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 60.629|Train Rec: -0.927 | Val loss: 60.632, Val Rec: -0.920\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 60.643|Train Rec: -0.913 | Val loss: 60.610, Val Rec: -0.941\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 60.640|Train Rec: -0.916 | Val loss: 60.553, Val Rec: -0.999\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 60.639|Train Rec: -0.919 | Val loss: 60.684, Val Rec: -0.868\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 60.672|Train Rec: -0.884 | Val loss: 60.550, Val Rec: -1.002\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 60.618|Train Rec: -0.938 | Val loss: 60.547, Val Rec: -1.005\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 60.621|Train Rec: -0.935 | Val loss: 60.561, Val Rec: -0.991\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 60.631|Train Rec: -0.924 | Val loss: 60.549, Val Rec: -1.003\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 60.616|Train Rec: -0.940 | Val loss: 60.533, Val Rec: -1.019\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_12_75_37\\modelb_12_75_37_ep40_norm0_bits2.4_bs128_lr0.005.pth\n",
      "Model: modelb_12_75_37_ep40_norm0_bits2.4_bs128_lr0.005 has been trained\n",
      "Using this model modelb_12_75_37_ep40_norm0_bits2.4_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_13_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15c202a4371449f8aa563d21b4e34f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 67.635| Val KL: 66.68074713812933 | Val Rec: 0.954\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 66.524|Train Rec: -0.169 | Val loss: 66.199, Val Rec: -0.482\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 66.090|Train Rec: -0.606 | Val loss: 66.067, Val Rec: -0.615\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 66.041|Train Rec: -0.656 | Val loss: 65.948, Val Rec: -0.733\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 65.981|Train Rec: -0.712 | Val loss: 66.002, Val Rec: -0.678\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 65.931|Train Rec: -0.762 | Val loss: 65.907, Val Rec: -0.774\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 65.913|Train Rec: -0.778 | Val loss: 65.860, Val Rec: -0.820\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 65.884|Train Rec: -0.805 | Val loss: 65.863, Val Rec: -0.817\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 65.879|Train Rec: -0.811 | Val loss: 66.017, Val Rec: -0.664\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 65.870|Train Rec: -0.818 | Val loss: 65.924, Val Rec: -0.756\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 65.843|Train Rec: -0.844 | Val loss: 65.827, Val Rec: -0.854\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 65.839|Train Rec: -0.850 | Val loss: 65.864, Val Rec: -0.816\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 65.842|Train Rec: -0.846 | Val loss: 65.819, Val Rec: -0.862\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 65.837|Train Rec: -0.851 | Val loss: 65.825, Val Rec: -0.856\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 65.823|Train Rec: -0.864 | Val loss: 65.858, Val Rec: -0.823\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 65.815|Train Rec: -0.872 | Val loss: 65.772, Val Rec: -0.909\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 65.796|Train Rec: -0.891 | Val loss: 65.752, Val Rec: -0.928\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 65.806|Train Rec: -0.880 | Val loss: 65.741, Val Rec: -0.940\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 65.790|Train Rec: -0.897 | Val loss: 65.782, Val Rec: -0.899\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 65.783|Train Rec: -0.904 | Val loss: 65.850, Val Rec: -0.831\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 65.771|Train Rec: -0.914 | Val loss: 65.727, Val Rec: -0.954\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 65.783|Train Rec: -0.903 | Val loss: 65.722, Val Rec: -0.959\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 65.772|Train Rec: -0.914 | Val loss: 65.746, Val Rec: -0.935\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 65.788|Train Rec: -0.898 | Val loss: 65.746, Val Rec: -0.935\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 65.770|Train Rec: -0.917 | Val loss: 65.849, Val Rec: -0.831\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 65.777|Train Rec: -0.908 | Val loss: 65.711, Val Rec: -0.970\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 65.773|Train Rec: -0.912 | Val loss: 65.730, Val Rec: -0.951\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 65.764|Train Rec: -0.922 | Val loss: 65.729, Val Rec: -0.952\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 65.749|Train Rec: -0.936 | Val loss: 65.729, Val Rec: -0.953\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 65.758|Train Rec: -0.927 | Val loss: 65.732, Val Rec: -0.948\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 65.758|Train Rec: -0.927 | Val loss: 65.727, Val Rec: -0.954\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 65.761|Train Rec: -0.925 | Val loss: 65.716, Val Rec: -0.964\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 65.763|Train Rec: -0.922 | Val loss: 65.682, Val Rec: -0.999\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 65.752|Train Rec: -0.933 | Val loss: 65.685, Val Rec: -0.996\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 65.743|Train Rec: -0.942 | Val loss: 65.678, Val Rec: -1.003\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 65.740|Train Rec: -0.945 | Val loss: 65.676, Val Rec: -1.006\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 65.738|Train Rec: -0.947 | Val loss: 65.691, Val Rec: -0.990\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 65.736|Train Rec: -0.949 | Val loss: 65.697, Val Rec: -0.984\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 65.730|Train Rec: -0.955 | Val loss: 65.659, Val Rec: -1.022\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 65.732|Train Rec: -0.953 | Val loss: 65.668, Val Rec: -1.013\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 65.730|Train Rec: -0.955 | Val loss: 65.677, Val Rec: -1.004\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_13_75_37\\modelb_13_75_37_ep40_norm0_bits2.6_bs128_lr0.005.pth\n",
      "Model: modelb_13_75_37_ep40_norm0_bits2.6_bs128_lr0.005 has been trained\n",
      "Using this model modelb_13_75_37_ep40_norm0_bits2.6_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_14_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa87d5c9caa46bbae94576af73f54f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 72.760| Val KL: 71.81005096435547 | Val Rec: 0.950\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 71.667|Train Rec: -0.157 | Val loss: 71.381, Val Rec: -0.430\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 71.211|Train Rec: -0.613 | Val loss: 71.112, Val Rec: -0.699\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 71.125|Train Rec: -0.698 | Val loss: 71.135, Val Rec: -0.676\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 71.085|Train Rec: -0.737 | Val loss: 71.004, Val Rec: -0.806\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 71.054|Train Rec: -0.767 | Val loss: 70.987, Val Rec: -0.823\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 71.022|Train Rec: -0.799 | Val loss: 71.058, Val Rec: -0.752\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 71.011|Train Rec: -0.808 | Val loss: 70.977, Val Rec: -0.833\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 71.008|Train Rec: -0.811 | Val loss: 71.078, Val Rec: -0.732\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 70.972|Train Rec: -0.846 | Val loss: 70.934, Val Rec: -0.876\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 70.980|Train Rec: -0.839 | Val loss: 70.929, Val Rec: -0.882\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 70.971|Train Rec: -0.847 | Val loss: 70.919, Val Rec: -0.891\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 70.950|Train Rec: -0.867 | Val loss: 70.943, Val Rec: -0.867\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 70.930|Train Rec: -0.887 | Val loss: 70.922, Val Rec: -0.888\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 70.929|Train Rec: -0.887 | Val loss: 70.918, Val Rec: -0.892\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 70.940|Train Rec: -0.876 | Val loss: 70.889, Val Rec: -0.921\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 70.918|Train Rec: -0.897 | Val loss: 70.890, Val Rec: -0.920\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 70.902|Train Rec: -0.913 | Val loss: 70.867, Val Rec: -0.943\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 70.908|Train Rec: -0.908 | Val loss: 70.925, Val Rec: -0.885\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 70.901|Train Rec: -0.914 | Val loss: 70.956, Val Rec: -0.854\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 70.895|Train Rec: -0.919 | Val loss: 70.915, Val Rec: -0.895\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 70.893|Train Rec: -0.921 | Val loss: 70.870, Val Rec: -0.940\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 70.900|Train Rec: -0.914 | Val loss: 70.889, Val Rec: -0.921\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 70.888|Train Rec: -0.926 | Val loss: 70.835, Val Rec: -0.975\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 70.889|Train Rec: -0.926 | Val loss: 70.841, Val Rec: -0.969\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 70.891|Train Rec: -0.923 | Val loss: 70.875, Val Rec: -0.937\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 70.890|Train Rec: -0.925 | Val loss: 70.867, Val Rec: -0.943\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 70.891|Train Rec: -0.924 | Val loss: 70.857, Val Rec: -0.954\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 70.879|Train Rec: -0.935 | Val loss: 70.809, Val Rec: -1.002\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 70.877|Train Rec: -0.938 | Val loss: 70.841, Val Rec: -0.969\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 70.864|Train Rec: -0.950 | Val loss: 70.794, Val Rec: -1.016\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 70.865|Train Rec: -0.949 | Val loss: 70.847, Val Rec: -0.963\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 70.864|Train Rec: -0.950 | Val loss: 70.831, Val Rec: -0.980\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 70.866|Train Rec: -0.948 | Val loss: 70.811, Val Rec: -0.999\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 70.850|Train Rec: -0.964 | Val loss: 70.819, Val Rec: -0.991\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 70.876|Train Rec: -0.938 | Val loss: 70.802, Val Rec: -1.008\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 70.877|Train Rec: -0.937 | Val loss: 70.771, Val Rec: -1.039\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 70.859|Train Rec: -0.955 | Val loss: 70.764, Val Rec: -1.046\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 70.852|Train Rec: -0.962 | Val loss: 70.771, Val Rec: -1.039\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 70.849|Train Rec: -0.965 | Val loss: 70.764, Val Rec: -1.046\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 70.854|Train Rec: -0.960 | Val loss: 70.772, Val Rec: -1.038\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_14_75_37\\modelb_14_75_37_ep40_norm0_bits2.8_bs128_lr0.005.pth\n",
      "Model: modelb_14_75_37_ep40_norm0_bits2.8_bs128_lr0.005 has been trained\n",
      "Using this model modelb_14_75_37_ep40_norm0_bits2.8_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_15_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cb49641d454d07af4ab26a45b36331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 77.893| Val KL: 76.9393310546875 | Val Rec: 0.953\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 76.767|Train Rec: -0.186 | Val loss: 76.365, Val Rec: -0.576\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 76.333|Train Rec: -0.620 | Val loss: 76.185, Val Rec: -0.755\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 76.232|Train Rec: -0.720 | Val loss: 76.189, Val Rec: -0.751\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 76.197|Train Rec: -0.753 | Val loss: 76.129, Val Rec: -0.810\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 76.178|Train Rec: -0.772 | Val loss: 76.153, Val Rec: -0.787\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 76.152|Train Rec: -0.795 | Val loss: 76.151, Val Rec: -0.789\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 76.140|Train Rec: -0.808 | Val loss: 76.193, Val Rec: -0.747\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 76.174|Train Rec: -0.777 | Val loss: 76.103, Val Rec: -0.836\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 76.130|Train Rec: -0.817 | Val loss: 76.141, Val Rec: -0.798\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 76.105|Train Rec: -0.843 | Val loss: 76.146, Val Rec: -0.794\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 76.178|Train Rec: -0.769 | Val loss: 76.134, Val Rec: -0.806\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 76.080|Train Rec: -0.866 | Val loss: 76.153, Val Rec: -0.787\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 76.073|Train Rec: -0.872 | Val loss: 76.065, Val Rec: -0.874\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 76.061|Train Rec: -0.884 | Val loss: 75.997, Val Rec: -0.942\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 76.057|Train Rec: -0.887 | Val loss: 76.163, Val Rec: -0.777\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 76.059|Train Rec: -0.886 | Val loss: 75.999, Val Rec: -0.940\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 76.038|Train Rec: -0.906 | Val loss: 76.037, Val Rec: -0.903\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 76.048|Train Rec: -0.896 | Val loss: 76.013, Val Rec: -0.927\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 76.044|Train Rec: -0.900 | Val loss: 76.070, Val Rec: -0.869\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 76.029|Train Rec: -0.915 | Val loss: 76.011, Val Rec: -0.929\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 76.025|Train Rec: -0.920 | Val loss: 75.994, Val Rec: -0.945\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 76.016|Train Rec: -0.928 | Val loss: 75.953, Val Rec: -0.986\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 76.019|Train Rec: -0.924 | Val loss: 75.963, Val Rec: -0.976\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 76.030|Train Rec: -0.913 | Val loss: 75.998, Val Rec: -0.942\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 76.007|Train Rec: -0.936 | Val loss: 75.989, Val Rec: -0.950\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 75.996|Train Rec: -0.947 | Val loss: 75.925, Val Rec: -1.015\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 76.010|Train Rec: -0.933 | Val loss: 75.961, Val Rec: -0.978\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 76.018|Train Rec: -0.925 | Val loss: 76.005, Val Rec: -0.934\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 76.002|Train Rec: -0.940 | Val loss: 75.973, Val Rec: -0.966\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 76.000|Train Rec: -0.943 | Val loss: 75.959, Val Rec: -0.981\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 75.995|Train Rec: -0.949 | Val loss: 76.001, Val Rec: -0.939\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 75.984|Train Rec: -0.960 | Val loss: 75.918, Val Rec: -1.022\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 75.992|Train Rec: -0.951 | Val loss: 75.948, Val Rec: -0.991\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 75.989|Train Rec: -0.954 | Val loss: 75.928, Val Rec: -1.011\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 75.981|Train Rec: -0.961 | Val loss: 75.942, Val Rec: -0.998\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 75.985|Train Rec: -0.958 | Val loss: 75.955, Val Rec: -0.984\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 75.998|Train Rec: -0.945 | Val loss: 75.913, Val Rec: -1.026\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 75.973|Train Rec: -0.970 | Val loss: 75.928, Val Rec: -1.011\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 75.994|Train Rec: -0.949 | Val loss: 75.923, Val Rec: -1.017\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 75.975|Train Rec: -0.968 | Val loss: 75.912, Val Rec: -1.027\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_15_75_37\\modelb_15_75_37_ep40_norm0_bits3.0_bs128_lr0.005.pth\n",
      "Model: modelb_15_75_37_ep40_norm0_bits3.0_bs128_lr0.005 has been trained\n",
      "Using this model modelb_15_75_37_ep40_norm0_bits3.0_bs128_lr0.005\n",
      "Directory already exists: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\n",
      "model path c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_16_75_37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2becd0df9f3b40e49a58a77633d414cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-training evaluation on the model in epoch 0\n",
      "\n",
      "Val loss: 103.546| Val KL: 102.58580017089844 | Val Rec: 0.960\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "Train loss: 102.420|Train Rec: -0.175 | Val loss: 102.050, Val Rec: -0.536\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "Train loss: 101.966|Train Rec: -0.628 | Val loss: 101.935, Val Rec: -0.651\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "Train loss: 101.856|Train Rec: -0.737 | Val loss: 101.800, Val Rec: -0.786\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "Train loss: 101.815|Train Rec: -0.778 | Val loss: 101.802, Val Rec: -0.784\n",
      "\n",
      "Epoch 5\n",
      "--------------------\n",
      "Train loss: 101.798|Train Rec: -0.794 | Val loss: 101.739, Val Rec: -0.847\n",
      "\n",
      "Epoch 6\n",
      "--------------------\n",
      "Train loss: 101.781|Train Rec: -0.811 | Val loss: 101.756, Val Rec: -0.829\n",
      "\n",
      "Epoch 7\n",
      "--------------------\n",
      "Train loss: 101.737|Train Rec: -0.854 | Val loss: 101.694, Val Rec: -0.892\n",
      "\n",
      "Epoch 8\n",
      "--------------------\n",
      "Train loss: 101.739|Train Rec: -0.857 | Val loss: 101.770, Val Rec: -0.817\n",
      "\n",
      "Epoch 9\n",
      "--------------------\n",
      "Train loss: 101.744|Train Rec: -0.847 | Val loss: 101.728, Val Rec: -0.858\n",
      "\n",
      "Epoch 10\n",
      "--------------------\n",
      "Train loss: 101.701|Train Rec: -0.888 | Val loss: 101.668, Val Rec: -0.918\n",
      "\n",
      "Epoch 11\n",
      "--------------------\n",
      "Train loss: 101.698|Train Rec: -0.896 | Val loss: 101.752, Val Rec: -0.834\n",
      "\n",
      "Epoch 12\n",
      "--------------------\n",
      "Train loss: 101.751|Train Rec: -0.840 | Val loss: 101.649, Val Rec: -0.937\n",
      "\n",
      "Epoch 13\n",
      "--------------------\n",
      "Train loss: 101.680|Train Rec: -0.909 | Val loss: 101.637, Val Rec: -0.949\n",
      "\n",
      "Epoch 14\n",
      "--------------------\n",
      "Train loss: 101.671|Train Rec: -0.918 | Val loss: 101.662, Val Rec: -0.924\n",
      "\n",
      "Epoch 15\n",
      "--------------------\n",
      "Train loss: 101.663|Train Rec: -0.926 | Val loss: 101.641, Val Rec: -0.944\n",
      "\n",
      "Epoch 16\n",
      "--------------------\n",
      "Train loss: 101.684|Train Rec: -0.907 | Val loss: 101.656, Val Rec: -0.930\n",
      "\n",
      "Epoch 17\n",
      "--------------------\n",
      "Train loss: 101.666|Train Rec: -0.923 | Val loss: 101.626, Val Rec: -0.960\n",
      "\n",
      "Epoch 18\n",
      "--------------------\n",
      "Train loss: 101.650|Train Rec: -0.938 | Val loss: 101.608, Val Rec: -0.978\n",
      "\n",
      "Epoch 19\n",
      "--------------------\n",
      "Train loss: 101.651|Train Rec: -0.937 | Val loss: 101.662, Val Rec: -0.923\n",
      "\n",
      "Epoch 20\n",
      "--------------------\n",
      "Train loss: 101.648|Train Rec: -0.941 | Val loss: 101.634, Val Rec: -0.952\n",
      "\n",
      "Epoch 21\n",
      "--------------------\n",
      "Train loss: 101.632|Train Rec: -0.956 | Val loss: 101.575, Val Rec: -1.010\n",
      "\n",
      "Epoch 22\n",
      "--------------------\n",
      "Train loss: 101.631|Train Rec: -0.957 | Val loss: 101.595, Val Rec: -0.991\n",
      "\n",
      "Epoch 23\n",
      "--------------------\n",
      "Train loss: 101.631|Train Rec: -0.957 | Val loss: 101.609, Val Rec: -0.976\n",
      "\n",
      "Epoch 24\n",
      "--------------------\n",
      "Train loss: 101.636|Train Rec: -0.952 | Val loss: 101.591, Val Rec: -0.995\n",
      "\n",
      "Epoch 25\n",
      "--------------------\n",
      "Train loss: 101.642|Train Rec: -0.946 | Val loss: 101.582, Val Rec: -1.003\n",
      "\n",
      "Epoch 26\n",
      "--------------------\n",
      "Train loss: 101.618|Train Rec: -0.970 | Val loss: 101.630, Val Rec: -0.956\n",
      "\n",
      "Epoch 27\n",
      "--------------------\n",
      "Train loss: 101.626|Train Rec: -0.962 | Val loss: 101.568, Val Rec: -1.017\n",
      "\n",
      "Epoch 28\n",
      "--------------------\n",
      "Train loss: 101.623|Train Rec: -0.965 | Val loss: 101.604, Val Rec: -0.982\n",
      "\n",
      "Epoch 29\n",
      "--------------------\n",
      "Train loss: 101.622|Train Rec: -0.966 | Val loss: 101.570, Val Rec: -1.016\n",
      "\n",
      "Epoch 30\n",
      "--------------------\n",
      "Train loss: 101.612|Train Rec: -0.975 | Val loss: 101.561, Val Rec: -1.025\n",
      "\n",
      "Epoch 31\n",
      "--------------------\n",
      "Train loss: 101.616|Train Rec: -0.972 | Val loss: 101.554, Val Rec: -1.032\n",
      "\n",
      "Epoch 32\n",
      "--------------------\n",
      "Train loss: 101.617|Train Rec: -0.971 | Val loss: 101.602, Val Rec: -0.984\n",
      "\n",
      "Epoch 33\n",
      "--------------------\n",
      "Train loss: 101.623|Train Rec: -0.964 | Val loss: 101.582, Val Rec: -1.004\n",
      "\n",
      "Epoch 34\n",
      "--------------------\n",
      "Train loss: 101.614|Train Rec: -0.973 | Val loss: 101.558, Val Rec: -1.028\n",
      "\n",
      "Epoch 35\n",
      "--------------------\n",
      "Train loss: 101.606|Train Rec: -0.982 | Val loss: 101.576, Val Rec: -1.010\n",
      "\n",
      "Epoch 36\n",
      "--------------------\n",
      "Train loss: 101.604|Train Rec: -0.984 | Val loss: 101.542, Val Rec: -1.044\n",
      "\n",
      "Epoch 37\n",
      "--------------------\n",
      "Train loss: 101.622|Train Rec: -0.969 | Val loss: 101.584, Val Rec: -1.002\n",
      "\n",
      "Epoch 38\n",
      "--------------------\n",
      "Train loss: 101.686|Train Rec: -0.901 | Val loss: 101.538, Val Rec: -1.048\n",
      "\n",
      "Epoch 39\n",
      "--------------------\n",
      "Train loss: 101.604|Train Rec: -0.984 | Val loss: 101.518, Val Rec: -1.068\n",
      "\n",
      "Epoch 40\n",
      "--------------------\n",
      "Train loss: 101.598|Train Rec: -0.989 | Val loss: 101.524, Val Rec: -1.062\n",
      "\n",
      "Model saved at: c:\\Users\\gpano\\Desktop\\github_py\\proteomics_latent_space\\models\\modelb_16_75_37\\modelb_16_75_37_ep40_norm0_bits4.0_bs128_lr0.005.pth\n",
      "Model: modelb_16_75_37_ep40_norm0_bits4.0_bs128_lr0.005 has been trained\n",
      "Using this model modelb_16_75_37_ep40_norm0_bits4.0_bs128_lr0.005\n"
     ]
    }
   ],
   "source": [
    "bitlst = [0,0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0,2.2,2.4,2.6,2.8,3.0,4.0]\n",
    "final_df = None\n",
    "for i, bits in enumerate(bitlst):\n",
    "    hidden_dim = 75\n",
    "    latent_dim = 37\n",
    "    n=i\n",
    "\n",
    "    # Instantiate the model\n",
    "    model1 = v1.VAE(\n",
    "        n_features=130,\n",
    "        latent_dim=latent_dim,\n",
    "        hidden_layer=True,\n",
    "        hidden_dim=hidden_dim,\n",
    "        sigmoid=True\n",
    "    ).to(device)\n",
    "\n",
    "    # need to set the model name with the layers - usefull for creating its unique folder \n",
    "    model_name = f\"modelb_{n}_{hidden_dim}_{latent_dim}\"\n",
    "\n",
    "    # the optimizer is in the train-val loop \n",
    "\n",
    "\n",
    "    ## Create a \"models\" folder and the specifics model's directory to save figures  \n",
    "\n",
    "    # create the models directory path \n",
    "    path_dir = os.getcwd() + \"\\\\models\"\n",
    "\n",
    "    # Check if the models directory exists, if not, create it\n",
    "    if not os.path.exists(path_dir):\n",
    "        os.makedirs(path_dir)\n",
    "        print(f\"Created directory: {path_dir}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {path_dir}\")\n",
    "\n",
    "    # create a subdirectory for each model based on #number and name (the dims of layers)\n",
    "    model_path = os.path.join(path_dir,model_name)\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    model_path\n",
    "\n",
    "\n",
    "    ## Final Important part\n",
    "\n",
    "    # set all the parameters to variables because all functions depend on them\n",
    "    model = model1\n",
    "    loss_fun = cf.loss_fun\n",
    "    model_name=model_name\n",
    "    path=model_path\n",
    "    epoch = 40\n",
    "    learn_r = 0.005\n",
    "    freebits = bits\n",
    "    batch_size = 128\n",
    "    norm = 0\n",
    "\n",
    "    # the path where this model is going to be saved \n",
    "    print(f\"model path {path}\")\n",
    "\n",
    "    # run the training for the model\n",
    "    # Run the loop - see the parameters \n",
    "\n",
    "    batch_dict, epoch_dict,hyperparam_str = uf.train_val_loop(\n",
    "    model = model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader, \n",
    "    loss_fun = loss_fun,\n",
    "    model_name=model_name,\n",
    "    model_path=path,\n",
    "    epoch = epoch,\n",
    "    learn_r = learn_r,\n",
    "    freebits = freebits,\n",
    "    batch_size = batch_size,\n",
    "    norm = norm\n",
    "    )\n",
    "\n",
    "    # write the full model id\n",
    "    model_id = model_name + \"_\" + hyperparam_str\n",
    "    print(f\"Model: {model_id} has been trained\")\n",
    "\n",
    "\n",
    "    # next run the test set analysis for the eaxh model and get the results test_iter_dict and test_metrics \n",
    "    test_iter_dict, test_metrics = uf.test_set_analysis(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    loss_fun = loss_fun,\n",
    "    freebits=freebits,\n",
    "    model_id=model_id\n",
    ")\n",
    "    test_df = pd.DataFrame([test_metrics])\n",
    "    if final_df is None:\n",
    "        final_df = test_df\n",
    "    else:\n",
    "        final_df = pd.concat([final_df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>bits</th>\n",
       "      <th>avg_total_loss</th>\n",
       "      <th>avg_kl_loss</th>\n",
       "      <th>avg_rl_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_0_75_37_ep40_norm0_bits0_bs128_lr0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056506</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.056485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_1_75_37_ep40_norm0_bits0.2_bs128_lr0.005</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.728092</td>\n",
       "      <td>5.132496</td>\n",
       "      <td>-0.404405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_2_75_37_ep40_norm0_bits0.4_bs128_lr0.005</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.683120</td>\n",
       "      <td>10.260596</td>\n",
       "      <td>-0.577476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_3_75_37_ep40_norm0_bits0.6_bs128_lr0.005</td>\n",
       "      <td>0.6</td>\n",
       "      <td>14.686883</td>\n",
       "      <td>15.388570</td>\n",
       "      <td>-0.701688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_4_75_37_ep40_norm0_bits0.8_bs128_lr0.005</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19.738088</td>\n",
       "      <td>20.517975</td>\n",
       "      <td>-0.779887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_5_75_37_ep40_norm0_bits1.0_bs128_lr0.005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.813657</td>\n",
       "      <td>25.646972</td>\n",
       "      <td>-0.833315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_6_75_37_ep40_norm0_bits1.2_bs128_lr0.005</td>\n",
       "      <td>1.2</td>\n",
       "      <td>29.878711</td>\n",
       "      <td>30.775991</td>\n",
       "      <td>-0.897279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_7_75_37_ep40_norm0_bits1.4_bs128_lr0.005</td>\n",
       "      <td>1.4</td>\n",
       "      <td>35.004935</td>\n",
       "      <td>35.905278</td>\n",
       "      <td>-0.900343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_8_75_37_ep40_norm0_bits1.6_bs128_lr0.005</td>\n",
       "      <td>1.6</td>\n",
       "      <td>40.107836</td>\n",
       "      <td>41.034768</td>\n",
       "      <td>-0.926932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_9_75_37_ep40_norm0_bits1.8_bs128_lr0.005</td>\n",
       "      <td>1.8</td>\n",
       "      <td>45.209466</td>\n",
       "      <td>46.163740</td>\n",
       "      <td>-0.954274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_10_75_37_ep40_norm0_bits2.0_bs128_lr0.005</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.308009</td>\n",
       "      <td>51.293046</td>\n",
       "      <td>-0.985037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_11_75_37_ep40_norm0_bits2.2_bs128_lr0.005</td>\n",
       "      <td>2.2</td>\n",
       "      <td>55.408707</td>\n",
       "      <td>56.422527</td>\n",
       "      <td>-1.013820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_12_75_37_ep40_norm0_bits2.4_bs128_lr0.005</td>\n",
       "      <td>2.4</td>\n",
       "      <td>60.523702</td>\n",
       "      <td>61.551616</td>\n",
       "      <td>-1.027914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_13_75_37_ep40_norm0_bits2.6_bs128_lr0.005</td>\n",
       "      <td>2.6</td>\n",
       "      <td>65.670739</td>\n",
       "      <td>66.681543</td>\n",
       "      <td>-1.010805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_14_75_37_ep40_norm0_bits2.8_bs128_lr0.005</td>\n",
       "      <td>2.8</td>\n",
       "      <td>70.764439</td>\n",
       "      <td>71.810507</td>\n",
       "      <td>-1.046068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_15_75_37_ep40_norm0_bits3.0_bs128_lr0.005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.906034</td>\n",
       "      <td>76.939603</td>\n",
       "      <td>-1.033568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelb_16_75_37_ep40_norm0_bits4.0_bs128_lr0.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.516179</td>\n",
       "      <td>102.585800</td>\n",
       "      <td>-1.069620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model_id  bits  avg_total_loss  \\\n",
       "0     modelb_0_75_37_ep40_norm0_bits0_bs128_lr0.005   0.0        0.056506   \n",
       "0   modelb_1_75_37_ep40_norm0_bits0.2_bs128_lr0.005   0.2        4.728092   \n",
       "0   modelb_2_75_37_ep40_norm0_bits0.4_bs128_lr0.005   0.4        9.683120   \n",
       "0   modelb_3_75_37_ep40_norm0_bits0.6_bs128_lr0.005   0.6       14.686883   \n",
       "0   modelb_4_75_37_ep40_norm0_bits0.8_bs128_lr0.005   0.8       19.738088   \n",
       "0   modelb_5_75_37_ep40_norm0_bits1.0_bs128_lr0.005   1.0       24.813657   \n",
       "0   modelb_6_75_37_ep40_norm0_bits1.2_bs128_lr0.005   1.2       29.878711   \n",
       "0   modelb_7_75_37_ep40_norm0_bits1.4_bs128_lr0.005   1.4       35.004935   \n",
       "0   modelb_8_75_37_ep40_norm0_bits1.6_bs128_lr0.005   1.6       40.107836   \n",
       "0   modelb_9_75_37_ep40_norm0_bits1.8_bs128_lr0.005   1.8       45.209466   \n",
       "0  modelb_10_75_37_ep40_norm0_bits2.0_bs128_lr0.005   2.0       50.308009   \n",
       "0  modelb_11_75_37_ep40_norm0_bits2.2_bs128_lr0.005   2.2       55.408707   \n",
       "0  modelb_12_75_37_ep40_norm0_bits2.4_bs128_lr0.005   2.4       60.523702   \n",
       "0  modelb_13_75_37_ep40_norm0_bits2.6_bs128_lr0.005   2.6       65.670739   \n",
       "0  modelb_14_75_37_ep40_norm0_bits2.8_bs128_lr0.005   2.8       70.764439   \n",
       "0  modelb_15_75_37_ep40_norm0_bits3.0_bs128_lr0.005   3.0       75.906034   \n",
       "0  modelb_16_75_37_ep40_norm0_bits4.0_bs128_lr0.005   4.0      101.516179   \n",
       "\n",
       "   avg_kl_loss  avg_rl_loss  \n",
       "0     0.000021     0.056485  \n",
       "0     5.132496    -0.404405  \n",
       "0    10.260596    -0.577476  \n",
       "0    15.388570    -0.701688  \n",
       "0    20.517975    -0.779887  \n",
       "0    25.646972    -0.833315  \n",
       "0    30.775991    -0.897279  \n",
       "0    35.905278    -0.900343  \n",
       "0    41.034768    -0.926932  \n",
       "0    46.163740    -0.954274  \n",
       "0    51.293046    -0.985037  \n",
       "0    56.422527    -1.013820  \n",
       "0    61.551616    -1.027914  \n",
       "0    66.681543    -1.010805  \n",
       "0    71.810507    -1.046068  \n",
       "0    76.939603    -1.033568  \n",
       "0   102.585800    -1.069620  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots Rec los vs bits \n",
    "fig, ax1 = plt.subplots(figsize=(12,8))\n",
    "ax1 = sns.lineplot(\n",
    "            final_df,x=final_df[\"bits\"], y=final_df[\"avg_rl_loss\"],\n",
    "            lw = 2, color = \"royalblue\", alpha = 0.7, label=\"Rec Error\",\n",
    "            marker = \"o\", markerfacecolor=\"black\")\n",
    "\n",
    "ax1.set_ylim([\n",
    "            np.min(final_df[\"avg_rl_loss\"])*1.05,\n",
    "            np.max(final_df[\"avg_rl_loss\"])*1.05\n",
    "            ])\n",
    "\n",
    "ax1.legend(frameon = False, ncol=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
