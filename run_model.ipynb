{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as nrd\n",
    "import os \n",
    "import sys\n",
    "\n",
    "# Pytorch modules \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# this for the custom Dataset \n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# for timing functions\n",
    "from timeit import default_timer as timer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Project Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\gpano\\\\Desktop\\\\github_py\\\\proteomics_latent_space'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check your current directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** Run the configuration file first `configs.py`. Importing this script and setting the seed and device parameters before importing any of the other modules ensures that evereything is sync.\n",
    "\n",
    "**Important** If you want *change the configuration parameters*, change them before importing and running the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing models_util.configs module\n",
      "First set device and seed for reproducibility.\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from models_util import configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seed: None, Device: None'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs.get_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n"
     ]
    }
   ],
   "source": [
    "# print the global variables\n",
    "print(configs.project_seed, configs.project_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During configuration random seed 888 has been set.\n",
      "888 cpu\n"
     ]
    }
   ],
   "source": [
    "configs.set_seed(888)\n",
    "device = configs.set_device(force_cpu=True)\n",
    "\n",
    "# global variables have changed too\n",
    "print(configs.project_seed, configs.project_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seed: 888, Device: cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see if the get function also agrees:\n",
    "configs.get_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the configurations values are assigned globally, we can import the modules. If this is working, we expect each module to access the **same** **seed** and **device** we set. We are also expecting generated numbers **inside the modules** to be reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During configuration random seed 888 has been set.\n",
      "Importing models_util.utility_functions, running in cpu with seed: 888\n"
     ]
    }
   ],
   "source": [
    "# Load home modules and check the device where they are running \n",
    "from models_util import utility_functions as uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During configuration random seed 888 has been set.\n",
      "Importing models_util.custom_dataset, running in cpu with seed: 888\n"
     ]
    }
   ],
   "source": [
    "from models_util import custom_dataset as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During configuration random seed 888 has been set.\n",
      "Importing models_util.cost_functions, running in cpu with seed: 888\n"
     ]
    }
   ],
   "source": [
    "from models_util import cost_functions as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During configuration random seed 888 has been set.\n",
      "Importing models_util.VAE1, running in cpu with seed: 888\n"
     ]
    }
   ],
   "source": [
    "from models_util import VAE1 as v1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCBC Data scale and split for VAE\n",
    "- We will perform min-max scaling to the TMT-Ratios of the proteomic SCBC data. <br>\n",
    "- It is important to use the non-missing min and max values of dataset row-by-row <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path and read the scbc data\n",
    "data_path = os.getcwd() + \"\\\\data\\\\processed\\\\\" \n",
    "scbc = pd.read_csv(data_path+\"protein_quant_merged.txt\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(104200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to numpy \n",
    "npscbc = scbc.to_numpy()\n",
    "np.isnan(npscbc).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10439, 1) (10439, 1) 0 0\n"
     ]
    }
   ],
   "source": [
    "# Get extreme values (non-missing) frome ach row. \n",
    "scbc_min = np.nanmin(npscbc, axis=1, keepdims=True)  # minimum among non-NaN\n",
    "scbc_max = np.nanmax(npscbc, axis=1,keepdims=True)  # maximum among non-NaN\n",
    "\n",
    "# check that that shapes and values are as expected \n",
    "print(scbc_max.shape,scbc_min.shape,np.isnan(scbc_max).sum(), np.isnan(scbc_min).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(104200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale data and check\n",
    "npscbc_scaled = (npscbc - scbc_min) /(scbc_max - scbc_min + 1e-8)\n",
    "np.isnan(npscbc_scaled).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7829, 130), (1044, 130), (1566, 130))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = uf.create_data_partition(\n",
    "    npscbc_scaled, test_perc=0.15, val=True, val_perc=0.1\n",
    ")\n",
    "train_data.shape, val_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test reproducibility by re-runing the function and checking the data in the first index of the matrix. We expect it to be the same. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
